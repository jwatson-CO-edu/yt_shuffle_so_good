{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030cd40b-d9dc-4e62-8944-5f928497aef0",
   "metadata": {},
   "source": [
    "`python3.11 -m pip install jupyterlab PyEnchant scipy numpy spotipy scikit-learn --user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f39117-48a7-4c24-8e7d-7a7c561bb53e",
   "metadata": {},
   "source": [
    "# Init & Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021216f0-751d-42c6-a049-0166f0eea696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pickle, os\n",
    "from math import ceil\n",
    "from random import randrange, choice, random\n",
    "from time import sleep\n",
    "from pprint import pprint\n",
    "from uuid import uuid4\n",
    "\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import enchant\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "from ShuffleSoGood import now\n",
    "\n",
    "## Client Info ##\n",
    "CLIENT_ID     = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "CLIENT_SCOPE  = \"user-follow-modify playlist-modify-private playlist-modify-public\"\n",
    "USER_NAME     = \"31ytgsr7wdmiaroy77msqpiupdsi\"\n",
    "REDIR_URI     = \"https://github.com/jwatson-CO-edu/yt_shuffle_so_good\"\n",
    "AUTH_URL      = 'https://accounts.spotify.com/api/token'\n",
    "BASE_URL      = 'https://api.spotify.com/v1/'\n",
    "\n",
    "## API Info ##\n",
    "_RESPONSE_LIMIT =  100\n",
    "_ARTIST_Q_LIM   =   50\n",
    "_MAX_OFFSET     = 1000\n",
    "_T_LOGIN_S      = 60.0 * 45 #5 #10 #20 # 25 # 50\n",
    "tLastAuth       = 0.0\n",
    "\n",
    "with open( \"../keys/spot_ID.txt\" , 'r' ) as f:\n",
    "    CLIENT_ID = f.readlines()[0].strip()\n",
    "\n",
    "with open( \"../keys/spot_SECRET.txt\" , 'r' ) as f:\n",
    "    CLIENT_SECRET = f.readlines()[0].strip()\n",
    "\n",
    "token = None\n",
    "spot  = None\n",
    "\n",
    "\n",
    "def check_API_token():\n",
    "    global tLastAuth, token, _T_LOGIN_S, spot\n",
    "    tNow    = now()\n",
    "    elapsed = tNow - tLastAuth\n",
    "    if elapsed >= _T_LOGIN_S:\n",
    "        token = util.prompt_for_user_token(\n",
    "            username      = USER_NAME,\n",
    "            scope         = CLIENT_SCOPE,\n",
    "            client_id     = CLIENT_ID,\n",
    "            client_secret = CLIENT_SECRET,\n",
    "            redirect_uri  = REDIR_URI\n",
    "        )\n",
    "        spot = spotipy.Spotify( auth = token )\n",
    "        print( token )\n",
    "        clear_output( wait = True )\n",
    "        sleep( 2 )\n",
    "        print( \"TOKEN OBTAINED\" )\n",
    "        tLastAuth = tNow\n",
    "    else:\n",
    "        print( f\"TOKEN STILL VALID, AGE: {elapsed/60.0:.2f} MINUTES\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643e4861-2fed-44bf-81d0-53af493d8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN OBTAINED\n"
     ]
    }
   ],
   "source": [
    "check_API_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d1583-abb2-4c30-af15-f43082b839ee",
   "metadata": {},
   "source": [
    "## Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ad3b37-1ec4-474d-adfc-fcad78f6f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "playlist = {\n",
    "    'study01' : \"0a2qoe6S7lYeZ6nlhZdA0v\",\n",
    "    'study02' : \"6gbtR2cBq5PvkghidCvvGk\",\n",
    "    'study03' : \"3o3lN2qntdEV7UKTuuC77K\",\n",
    "    'study04' : \"41sFSisljvBDMBXtpp5NIw\",\n",
    "    'study05' : \"02iS5AFGp8YVuUUqcQf8ys\",\n",
    "    'study06' : \"6KI7A4MWrSM7EyKRUjxIi1\",\n",
    "    'study07' : \"3V055Md2JdrUT8tX0af7di\",\n",
    "    'study08' : \"0tspdJlwSgiyf2O9PO6QaP\",\n",
    "    'study09' : \"5mHRBFoQtYy2izeZ66pG95\",\n",
    "    'study10' : \"3832xeKGEOAXFJqE4K8kIq\",\n",
    "    'study11' : \"65MXR4dubPL9t0P4dgTWvn\",\n",
    "    'study12' : \"0ecSAfnD4CulIVnLt26ukI\",\n",
    "    'study13' : \"7K9ucByFRgDuZk8KMHeJkL\",\n",
    "    'study14' : \"0v26bHydUxcGC5EbMlkjzG\",\n",
    "    'study15' : \"6SqlfurCBP7eeMOojaDNtS\",\n",
    "    'study16' : \"5TtKaKCouyJp7Hhtu4YlYm\",\n",
    "    'study17' : \"5qX1Tq3IQ74iSgrlMfRhty\",\n",
    "    'study18' : \"1bwXMYoRgEFWebWZ9ZPBqs\",\n",
    "    'study19' : \"3ackEOD2vox5Oc1vjeALKJ\", \n",
    "    'study20' : \"3Cmpe4nGzOQDefowW49pBS\",\n",
    "}\n",
    "\n",
    "review = {\n",
    "    'zk_Over' : \"1diwH003mkfg3cLejTuKTN\", \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857e3ff-a087-4b18-933b-58398c97b3c6",
   "metadata": {},
   "source": [
    "## Session Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286a1d0-44c5-4e62-806b-92cc25990484",
   "metadata": {},
   "source": [
    "* FILTER TYPES: {'album', 'artist', 'track', 'year', 'upc', 'tag:hipster', 'tag:new', 'isrc', 'genre',}\n",
    "* SEARCH TYPES: {\"album\", \"artist\", \"playlist\", \"track\", \"show\", \"episode\", \"audiobook\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc80895-221f-454c-9595-448136e21407",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Session Database Params #####\n",
    "_MOD_T_DAY_S  = 60.0 * 60 * 24\n",
    "_STALE_TIME_S = _MOD_T_DAY_S * 31\n",
    "_NULL_GENRE   = \"Music\"\n",
    "_DATA_DIR     = \"data/\"\n",
    "_DATA_PREFIX  = \"Study-Music-Data_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13120a9-81f1-4e7a-a86e-ee7112d4247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShuffleSoGood import init_session_database\n",
    "data, timestamp, outFilNam, outPath = init_session_database( _DATA_PREFIX )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5d090-4c12-4c71-b203-db3f04ff3aaf",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dad2c0-697c-4260-8803-e169f90bcce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## General Params ##\n",
    "_N_BACKFILL  = 400\n",
    "_N_GN_CHUNK  = 100 # 50 # 200\n",
    "_N_RM_CHUNK  = 125 #500\n",
    "_NAME_PT_LIM =   6\n",
    "\n",
    "## Search 01 Params ##\n",
    "_N_MAX_SEARCH = 50\n",
    "_N_DEF_SEARCH = 10\n",
    "_YEAR_PADDING =  5\n",
    "\n",
    "## DBSCAN Params ##\n",
    "_DBS_EPSILON  =  0.7500 # 0.200 # 0.300 # 0.400 # 0.500 # 0.750\n",
    "_DBS_MIN_MMBR =  3\n",
    "\n",
    "## Mini-Genre Params ##\n",
    "_MRG_D_FACTOR =  1.25 # 1.0 # 1.5 # 2.0 #3.0\n",
    "_MIN_GNR_MMBR =  7\n",
    "_ONE_BILLION  = 1e9\n",
    "\n",
    "## Query History Keys ##\n",
    "_NU_REL_Q_KEY = \"NewReleases:Albums\" # Query Key for New Releases\n",
    "_FEAT_PL_Q_KY = \"Featured:Playlists\" # Query Key for Featured Playlists\n",
    "_ART_Q_PREFIX = \"ArtistTopTracks:\" # - Query Key Prefix for Artist Top Tracks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb873d77-71a8-4c02-a634-c45c6a95484e",
   "metadata": {},
   "source": [
    "# Function Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5d2a07-f5f3-4017-be37-cba6c46bea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOAD_DB_PKL = False\n",
    "_REGEN_DBASE = True\n",
    "_SEARCH_BKFL = False\n",
    "_FILL_PL_ID  = review['zk_Over']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ffb0b-076d-4a9b-b61b-3edd6eaf453d",
   "metadata": {},
   "source": [
    "# Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47479693-70ea-4f59-9413-385bb4c3a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_length( playlist_ID ):\n",
    "    \"\"\" Get the number of total tracks in the playlist \"\"\"\n",
    "    response = spot.user_playlist_tracks(\n",
    "        CLIENT_ID, \n",
    "        playlist_ID, \n",
    "        fields = 'items,uri,name,id,total', \n",
    "        limit  = _RESPONSE_LIMIT\n",
    "    )\n",
    "    return response['total']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b8bd7-c2cf-409a-bc12-116226f7e5a8",
   "metadata": {},
   "source": [
    "# File Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "310a7f5e-a553-4421-967d-696b4602f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShuffleSoGood import update_music_database, load_music_database, save_music_database, genre_vector_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf023d-baf6-4a19-8726-e0ead64c6400",
   "metadata": {},
   "source": [
    "# Search Version 01, Query by Existing Artist and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08fd9234-c1e2-4b5d-8622-0f5039a817c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_artist_within_era( artistName, releaseDate, \n",
    "                              N = _N_MAX_SEARCH, yearPadding = _YEAR_PADDING, pause_s = 0.5 ):\n",
    "    \"\"\" Return `N` tracks within `yearPadding` of `trackDict` and by the same artist \"\"\"\n",
    "    global data\n",
    "    rtnLs = list()\n",
    "    query = \"artist%3A\" + str( artistName ).replace( \" \", \"%20\")\n",
    "    try:\n",
    "        rYear = int( str( releaseDate )[:4] )\n",
    "    except Exception:\n",
    "        rYear = 2024\n",
    "    bYear   = rYear - yearPadding\n",
    "    eYear   = rYear + yearPadding\n",
    "    years   = list( range( bYear, eYear+1 ) )\n",
    "    miniLim = max( int(N/(eYear - bYear)), 1 )\n",
    "    Nloop   = int(N / miniLim * 2)\n",
    "    for i in range( Nloop ):\n",
    "        iYear = choice( years )\n",
    "        qry_i = query + \"%20year%3A\" + str( iYear )\n",
    "        print( f\"Search: {qry_i}\" )\n",
    "\n",
    "        if (data is not None):\n",
    "            if (qry_i in data['queries']):\n",
    "                ofst = data['queries'][ qry_i ]\n",
    "                data['queries'][ qry_i ] += miniLim\n",
    "            else:\n",
    "                ofst = 0\n",
    "                data['queries'][ qry_i ] = miniLim\n",
    "        else:\n",
    "            ofst = 0\n",
    "        \n",
    "        res = spot.search( qry_i, \n",
    "                           limit  = miniLim, \n",
    "                           offset = min( ofst, _MAX_OFFSET ), \n",
    "                           type   = 'track' )\n",
    "        sleep( pause_s )\n",
    "        \n",
    "        # tracks_i = [item['id'] for item in res['tracks']['items']]\n",
    "        tracks_i = res['tracks']['items']\n",
    "        \n",
    "        if (data is not None):\n",
    "            tracks_ii = list()\n",
    "            for trk_j in tracks_i:\n",
    "                if trk_j['id'] not in data['collectID']:\n",
    "                    tracks_ii.append( trk_j )\n",
    "            tracks_i = tracks_ii[:]\n",
    "\n",
    "        rem = N - len( rtnLs )\n",
    "        if len( tracks_i ) > rem:\n",
    "            rtnLs.extend( tracks_i[:rem] )\n",
    "            return rtnLs\n",
    "        else:\n",
    "            rtnLs.extend( tracks_i )\n",
    "            # sleep( pause_s )\n",
    "    return rtnLs\n",
    "\n",
    "\n",
    "def choose_N_artist_year_pairs_from_db( N ):\n",
    "    \"\"\" Fetch `N` random (<Artist>, <Date>) pairs from the `data` for searching \"\"\"\n",
    "    global data\n",
    "    rtnPairs = list()\n",
    "    artList  = list( data['artists'].keys() )\n",
    "    print( f\"How Many Artists?: {len(artList)}\" )\n",
    "    for i in range(N):\n",
    "        artKey_i = choice( artList )\n",
    "        artist_i = data['artists'][ artKey_i ]['name']\n",
    "        rlYear_i = choice( data['artists'][ artKey_i ]['releases'] ) if len( data['artists'][ artKey_i ]['releases'] ) else '2024'\n",
    "        rtnPairs.append( (artist_i, rlYear_i,) )\n",
    "    return rtnPairs\n",
    "\n",
    "\n",
    "def basic_new_music_search_01( Ntot, Mper = 5, pause_s = 0.125 ):\n",
    "    \"\"\" Choose random `data` entries as search queries, Return a list of `Ntot` tracks consisting of `Mper` entries for each artist \"\"\"  \n",
    "    global data\n",
    "    rtnLst   = list()\n",
    "    searches = choose_N_artist_year_pairs_from_db( int( ceil( Ntot/Mper ) )*2 )\n",
    "    addSet   = set([])\n",
    "    for (art_i, rel_i) in searches:\n",
    "        print( f\"\\tSearch, Artist: {art_i}, Around Year: {rel_i}\" )\n",
    "        rem    = Ntot - len( rtnLst )\n",
    "        Mper   = min( Mper, rem )\n",
    "        trks   = search_artist_within_era( art_i, rel_i, N = Mper, yearPadding = 3, pause_s = 0.5 )\n",
    "        trks_i = list()\n",
    "        for trk in trks:\n",
    "            if trk['id'] not in addSet:\n",
    "                trks_i.append( trk )\n",
    "                addSet.add( trk['id'] )\n",
    "        rem = Ntot - len( rtnLst )\n",
    "        if rem > len( trks_i ):\n",
    "            rtnLst.extend( trks_i )\n",
    "        else:\n",
    "            rtnLst.extend( trks_i[ :rem ] )\n",
    "            break\n",
    "        sleep( pause_s )\n",
    "        check_API_token()\n",
    "    return rtnLst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f26f5-5906-409a-9093-eb48d1c17156",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab8a170-ba6c-41a4-a851-7bdb13d07bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########## CONTAINER FUNCTIONS #####################################################################\n",
    "\n",
    "def sort_keys_by_value( dct, reverse = True ):\n",
    "    \"\"\" Return a list of keys sorted by their (numeric) values \"\"\"\n",
    "    srtLst = list()\n",
    "    for k, v in dct.items():\n",
    "        srtLst.append( [v,k,] )\n",
    "    srtLst.sort( key = lambda x: x[0], reverse = reverse )\n",
    "    return [pair[1] for pair in srtLst] \n",
    "\n",
    "\n",
    "\n",
    "########## STRING ANALYSIS #########################################################################\n",
    "from collections import deque\n",
    "\n",
    "def levenshtein_dist( s1, s2 ):\n",
    "    \"\"\" Get the edit distance between two strings \"\"\"\n",
    "    # Author: Salvador Dali, https://stackoverflow.com/a/32558749\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = deque()\n",
    "        distances_.append( i2+1 )\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        # distances = distances_\n",
    "    # return distances[-1]\n",
    "    return distances_.pop()\n",
    "\n",
    "\n",
    "########## STATS & SAMPLING ########################################################################\n",
    "\n",
    "\n",
    "def total_pop( odds ):\n",
    "    \"\"\" Sum over all categories in the prior odds \"\"\"\n",
    "    total = 0\n",
    "    for k in odds:\n",
    "        total += odds[k]\n",
    "    return total\n",
    "\n",
    "\n",
    "def normalize_dist( odds_ ):\n",
    "    \"\"\" Normalize the distribution so that the sum equals 1.0 \"\"\"\n",
    "    total  = total_pop( odds_ )\n",
    "    rtnDst = dict()\n",
    "    for k in odds_:\n",
    "        rtnDst[k] = odds_[k] / total\n",
    "    return rtnDst\n",
    "\n",
    "\n",
    "def roll_outcome( odds ):\n",
    "    \"\"\" Get a random outcome from the distribution \"\"\"\n",
    "    oddsNorm = normalize_dist( odds )\n",
    "    distrib  = []\n",
    "    outcome  = []\n",
    "    total    = 0.0\n",
    "    for o, p in oddsNorm.items():\n",
    "        total += p\n",
    "        distrib.append( total )\n",
    "        outcome.append( o )\n",
    "    roll = random()\n",
    "    for i, p in enumerate( distrib ):\n",
    "        if roll <= p:\n",
    "            return outcome[i]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c7cc5-3ed3-4d66-892a-5e7199864955",
   "metadata": {},
   "source": [
    "# Mini-Genre Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee84d7bf-784a-4e06-a2b8-a5ee7ca2b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShuffleSoGood import get_tracks_as_vectors, _V_NUM_FEATURES\n",
    "\n",
    "def fetch_entire_playlist_with_audio_features( playlist_ID, pause_s = 1.00, disableFeatures = True ):\n",
    "    \"\"\" Get maximum infodump on all playlist tracks \"\"\"\n",
    "\n",
    "    plTracks = []\n",
    "    Ntracks  = get_playlist_length( playlist_ID )\n",
    "    trCount  = 0\n",
    "    trOffst  = 0\n",
    "\n",
    "    while trCount < Ntracks:\n",
    "\n",
    "        lim = min( _RESPONSE_LIMIT, Ntracks-trCount )\n",
    "\n",
    "        resTracks = None\n",
    "        while resTracks is None:\n",
    "            response = spot.user_playlist_tracks(\n",
    "                CLIENT_ID, \n",
    "                playlist_ID, \n",
    "                fields = 'items,uri,name,id,total', \n",
    "                limit  = lim,\n",
    "                offset = trCount\n",
    "            )\n",
    "            \n",
    "            sleep( pause_s )\n",
    "\n",
    "            if len( response['items'] ):\n",
    "                trCount  += len( response['items'] )\n",
    "                resTracks = response['items']\n",
    "                if disableFeatures:\n",
    "                    plTracks.extend( resTracks )\n",
    "\n",
    "        if not disableFeatures:\n",
    "            resIDs  = list()\n",
    "                \n",
    "            for item in resTracks:\n",
    "                resIDs.append( item['track']['id'] )\n",
    "                resFeatrs = None\n",
    "    \n",
    "            while resFeatrs is None:\n",
    "                resFeatrs = spot.audio_features( resIDs )\n",
    "                # pprint( resFeatrs[0] )\n",
    "                sleep( pause_s )\n",
    "    \n",
    "            if resTracks is not None:\n",
    "                for i, track_i in enumerate( resTracks ):\n",
    "                    track_i.update( resFeatrs[i] )\n",
    "        \n",
    "                plTracks.extend( resTracks )\n",
    "\n",
    "    return plTracks\n",
    "\n",
    "\n",
    "def assign_vectors_to_tracks( tracks ):\n",
    "    \"\"\" Store vector info in each track dictionary \"\"\"\n",
    "    matxTrks = get_tracks_as_vectors( tracks )\n",
    "    for i, vec_i in enumerate( matxTrks ):\n",
    "        trk_i = tracks[i]\n",
    "        trk_i['vector'] = vec_i\n",
    "    print( f\"Stored vectors for {len(tracks)} tracks!\" )\n",
    "\n",
    "\n",
    "def fetch_collection_with_audio_features( plDct, rvDct = None, pause_s = 3.0, renewSets = True, disableFeatures = True ):\n",
    "    \"\"\" Get maximum infodump on all playlists \"\"\"\n",
    "    global data\n",
    "\n",
    "    if renewSets:\n",
    "        data['collectID'] = set([])\n",
    "    \n",
    "    print( \"##### Get Collection Data #####\" )\n",
    "    for plName_i, plID_i in plDct.items():\n",
    "        print( plName_i, '-', plID_i, '...' )\n",
    "        tracks_i = fetch_entire_playlist_with_audio_features( plID_i, disableFeatures = disableFeatures )\n",
    "        if not disableFeatures:\n",
    "            assign_vectors_to_tracks( tracks_i )\n",
    "        data['playlists'][ plName_i ] = {\n",
    "            'ID'    : plID_i,\n",
    "            'tracks': tracks_i,\n",
    "            'len'   : len( tracks_i ),\n",
    "        }\n",
    "        data['collectID'] = data['collectID'].union( set([trk['track']['id'] for trk in tracks_i]) )\n",
    "\n",
    "        # Catalog artists from collection tracks (Req'd for (Sub-)Search 01)\n",
    "        for track_j in tracks_i:\n",
    "            for artist_k in track_j['track']['artists']:\n",
    "                artistID_j = artist_k['id']\n",
    "                if artistID_j not in data['artists']:\n",
    "                    data['artists'][ artistID_j ] = { \n",
    "                        'name'    : track_j['track']['artists'][0]['name'], \n",
    "                        'count'   : 1, \n",
    "                        'releases': [track_j['track']['album']['release_date'],], \n",
    "                    }\n",
    "                else:\n",
    "                    data['artists'][ artistID_j ]['count'   ] += 1\n",
    "                    data['artists'][ artistID_j ]['releases'].append( track_j['track']['album']['release_date'] )\n",
    "        \n",
    "        sleep( pause_s )\n",
    "\n",
    "    if (rvDct is not None) and (not disableFeatures):\n",
    "        print( \"\\n##### Get Review Data #####\" )\n",
    "        for plName_i, plID_i in rvDct.items():\n",
    "            print( plName_i, '-', plID_i, '...' )\n",
    "            tracks_i = fetch_entire_playlist_with_audio_features( plID_i )\n",
    "            assign_vectors_to_tracks( tracks_i )\n",
    "            data['review'][ plName_i ] = {\n",
    "                'ID'    : plID_i,\n",
    "                'tracks': tracks_i,\n",
    "                'len'   : len( tracks_i ),\n",
    "            }\n",
    "            data['reviewID'] = data['reviewID'].union( set([trk['track']['id'] for trk in tracks_i]) )\n",
    "            sleep( pause_s )\n",
    "\n",
    "    print( \"\\n##### Complete #####\" )\n",
    "\n",
    "\n",
    "def analyze_db_vector_spread( ):\n",
    "    \"\"\" Gather info for feature scaling and print it for manual scaling update \"\"\"\n",
    "    global data\n",
    "    rtnMatx = np.ones( (2, _V_NUM_FEATURES,) )\n",
    "    rtnMatx[0,:] *=  1e6\n",
    "    rtnMatx[1,:] *= -1e6\n",
    "    totlDct = dict()\n",
    "    totlDct.update( data['playlists'] )\n",
    "    totlDct.update( data['review'   ] )\n",
    "    for plName_i, playls_i in totlDct.items():\n",
    "        if len( playls_i['tracks'] ):\n",
    "            matx_i = get_tracks_as_vectors( playls_i['tracks'] )\n",
    "            mMin_i = np.min( matx_i, axis = 0 )\n",
    "            mMax_i = np.max( matx_i, axis = 0 )\n",
    "            for j in range( _V_NUM_FEATURES ):\n",
    "                if mMin_i[j] < rtnMatx[0,j]:\n",
    "                    rtnMatx[0,j] = mMin_i[j]\n",
    "                if mMax_i[j] > rtnMatx[1,j]:\n",
    "                    rtnMatx[1,j] = mMax_i[j]\n",
    "    for j in range( _V_NUM_FEATURES ):\n",
    "        print( f\"Feature {j+1}, Span: {rtnMatx[1,j] - rtnMatx[0,j]}, Min: {rtnMatx[0,j]}\" )\n",
    "    return rtnMatx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d20527d-9083-4786-b2f4-ed75f68ac371",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _LOAD_DB_PKL:\n",
    "    data = load_music_database( data, _DATA_DIR, _DATA_PREFIX, forceLoad = 1 );\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d7a880-7e42-4096-be6b-63f04f222b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Get Collection Data #####\n",
      "study01 - 0a2qoe6S7lYeZ6nlhZdA0v ...\n",
      "study02 - 6gbtR2cBq5PvkghidCvvGk ...\n",
      "study03 - 3o3lN2qntdEV7UKTuuC77K ...\n",
      "study04 - 41sFSisljvBDMBXtpp5NIw ...\n",
      "study05 - 02iS5AFGp8YVuUUqcQf8ys ...\n",
      "study06 - 6KI7A4MWrSM7EyKRUjxIi1 ...\n",
      "study07 - 3V055Md2JdrUT8tX0af7di ...\n",
      "study08 - 0tspdJlwSgiyf2O9PO6QaP ...\n",
      "study09 - 5mHRBFoQtYy2izeZ66pG95 ...\n",
      "study10 - 3832xeKGEOAXFJqE4K8kIq ...\n",
      "study11 - 65MXR4dubPL9t0P4dgTWvn ...\n",
      "study12 - 0ecSAfnD4CulIVnLt26ukI ...\n",
      "study13 - 7K9ucByFRgDuZk8KMHeJkL ...\n",
      "study14 - 0v26bHydUxcGC5EbMlkjzG ...\n",
      "study15 - 6SqlfurCBP7eeMOojaDNtS ...\n",
      "study16 - 5TtKaKCouyJp7Hhtu4YlYm ...\n",
      "study17 - 5qX1Tq3IQ74iSgrlMfRhty ...\n",
      "study18 - 1bwXMYoRgEFWebWZ9ZPBqs ...\n",
      "study19 - 3ackEOD2vox5Oc1vjeALKJ ...\n",
      "study20 - 3Cmpe4nGzOQDefowW49pBS ...\n",
      "\n",
      "##### Complete #####\n"
     ]
    }
   ],
   "source": [
    "if _REGEN_DBASE:\n",
    "    fetch_collection_with_audio_features( playlist, review, pause_s = 3.0 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65282a9b-a66d-4500-8433-4bc30e89cf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "About to write data/Study-Music-Data_2025-06-21T10:47:36.pkl ...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'data/Study-Music-Data_2025-06-21T10:47:36.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     analyze_db_vector_spread(  );\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;28mlen\u001b[39m( outPath ) )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43msave_music_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutPath\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/james/FILEPILE/Media/yt_shuffle_so_good/spotify/ShuffleSoGood.py:216\u001b[39m, in \u001b[36msave_music_database\u001b[39m\u001b[34m(dataDct, outPath)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Pickle `dataDct` to store current music collection data as well as search activity \"\"\"\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mprint\u001b[39m( \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAbout to write \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43moutPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    217\u001b[39m     pickle.dump( dataDct, f )\n\u001b[32m    218\u001b[39m \u001b[38;5;28mprint\u001b[39m( \u001b[33m\"\u001b[39m\u001b[33mCOMPLETE!\u001b[39m\u001b[33m\"\u001b[39m )\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: 'data/Study-Music-Data_2025-06-21T10:47:36.pkl'"
     ]
    }
   ],
   "source": [
    "if _REGEN_DBASE:\n",
    "    if 0:\n",
    "        analyze_db_vector_spread(  );\n",
    "    print( len( outPath ) )\n",
    "    save_music_database( data, outPath )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433707b-d993-49da-b535-5d83103ddcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_disallowed_entries_by_key( dct ):\n",
    "    \"\"\" Remove segments unsuitable for a genre name \"\"\"\n",
    "    # 2024-09-02: THERE ARE RACIAL SLURS IN THE PyEnchant MODULE! WHY?!? (Also: HITLER)\n",
    "    blocked = ['soundtrack', 'for', 'nigger', 'gypsy', 'Hitler', 'klan',] \n",
    "    qKeys   = list( dct.keys() )\n",
    "    qLen    = len( qKeys )\n",
    "    delSet  = set([])\n",
    "    difFrac = 0.25\n",
    "    for i, k in enumerate( qKeys ):\n",
    "        kLo     = str(k).lower()\n",
    "        removed = False\n",
    "        # Remove short keys\n",
    "        if (len( kLo.strip() ) <= 2) and (k in dct):\n",
    "            del dct[k]\n",
    "            removed = True\n",
    "        # Remove keys with apostrophees\n",
    "        elif (\"'\" in kLo) and (k in dct):\n",
    "            del dct[k]\n",
    "            removed = True\n",
    "        # Remove keys too similar to the blocked list\n",
    "        else:\n",
    "            for blkd in blocked:\n",
    "                if ((levenshtein_dist( kLo, blkd ) / len( blkd )) < difFrac) and (k in dct):\n",
    "                    del dct[k]\n",
    "                    removed = True\n",
    "                    break\n",
    "        # If the current key is suitable, Then remove all following keys that are too similar\n",
    "        if not removed:\n",
    "            for j in range( i+1, qLen ):\n",
    "                key_j    = qKeys[j]\n",
    "                if (key_j in dct):\n",
    "                    key_jLo  = str( key_j ).lower()\n",
    "                    distance = levenshtein_dist( kLo, key_jLo )\n",
    "                    fracRght = distance / len( key_jLo )\n",
    "                    fracLeft = distance / len( kLo     )\n",
    "                    if (fracRght < difFrac) or (fracLeft < difFrac):\n",
    "                        if key_j in dct:\n",
    "                            del dct[ key_j ]\n",
    "                        \n",
    "\n",
    "def repair_keys( dct ):\n",
    "    \"\"\" Replace keys that have characters we don't like \"\"\"\n",
    "    badChars = ['(', ')', ':', '\"']\n",
    "    dctKeys  = list( dct.keys() )\n",
    "    for key in dctKeys:\n",
    "        nuKey = str( key )\n",
    "        p_bad = False\n",
    "        for ch in badChars:\n",
    "            if ch in key:\n",
    "                nuKey.replace( ch, '' )\n",
    "                p_bad = True\n",
    "        if p_bad and (key in dct):\n",
    "            dct[ nuKey ] = dct[ key ]\n",
    "            del dct[ key ]\n",
    "\n",
    "\n",
    "def Proper_Namify( namStr ):\n",
    "    \"\"\" Capitalize every split string, and reassemble \"\"\"\n",
    "    namSeg = str( namStr ).split()\n",
    "    Nseg   = len( namSeg )\n",
    "    rtnNam = \"\"\n",
    "    for i, seg in enumerate( namSeg ):\n",
    "        rtnNam += seg[0].upper() + seg[1:].lower()\n",
    "        if i+1 < Nseg:\n",
    "            rtnNam += ' '\n",
    "    return rtnNam\n",
    "    \n",
    "\n",
    "def extract_and_generate_genre_names( genreDct, pause_s = 0.25 ):\n",
    "    \"\"\" Extract Spotify genre and Generate local genre \"\"\"\n",
    "    global data\n",
    "    mainDist = dict()\n",
    "    loclDist = dict()\n",
    "    artSet   = set([])\n",
    "    englishD = enchant.Dict( \"en_US\" )\n",
    "    segments = list()\n",
    "    # Get artist info and local genre candidate substrings\n",
    "    for track in genreDct['tracks']:\n",
    "        # Gather artist IDs\n",
    "        for artist in track['track']['album']['artists']:\n",
    "            artSet.add( artist['id'] )\n",
    "            segments.extend( artist['name'].split() )\n",
    "        # Gather naming strings\n",
    "        segments.extend( track['track']['album']['name'].split() )\n",
    "        segments.extend( track['track']['name'].split() )\n",
    "    qSegmnts = segments[:]\n",
    "    nglshSeg = list()\n",
    "    Norig    = len( segments )\n",
    "    for qSeg in qSegmnts:\n",
    "        segments.extend( englishD.suggest( qSeg ) ) # https://stackoverflow.com/a/3789057\n",
    "    for i, seg in enumerate( segments ):\n",
    "        if i < Norig:\n",
    "            value = 1.0\n",
    "        else:\n",
    "            value = 0.5\n",
    "        if seg in loclDist:\n",
    "            loclDist[ seg ] += value\n",
    "        else:\n",
    "            loclDist[ seg ]  = value\n",
    "    \n",
    "    repair_keys( loclDist )\n",
    "    remove_disallowed_entries_by_key( loclDist )\n",
    "    # pprint( loclDist )\n",
    "\n",
    "    # Extract Spotify genre from the artist set\n",
    "    artSetLs = list( artSet )\n",
    "    Nartists = len( artSetLs )\n",
    "    artQList = list()\n",
    "    if Nartists <= _ARTIST_Q_LIM:\n",
    "        artQList.append( artSetLs )\n",
    "    else:\n",
    "        bgn = 0\n",
    "        end = 0\n",
    "        while end < Nartists:\n",
    "            bgn = end\n",
    "            end = min( end+_ARTIST_Q_LIM, Nartists )\n",
    "            artQList.append( artSetLs[bgn:end] )\n",
    "\n",
    "    for qArtLs in artQList:\n",
    "        nuLst = list()\n",
    "        for qArtist in qArtLs:\n",
    "            if (qArtist not in data['artists']):\n",
    "                data['artists'][ qArtist ] = { \n",
    "                    'name'    : None, \n",
    "                    'count'   : 0, \n",
    "                    'releases': list(), \n",
    "                    'genres'  : list(), \n",
    "                }\n",
    "            if ('genres' not in data['artists'][ qArtist ]):\n",
    "                data['artists'][ qArtist ]['genres'] = list()\n",
    "            if (len( data['artists'][ qArtist ]['genres'] ) == 0):\n",
    "                nuLst.append( qArtist )\n",
    "\n",
    "        if len( nuLst ):\n",
    "            check_API_token() # 2024-09-01: WHY DOES IT KEEP FAILING HERE IT HAS NOT BEEN AN HOUR\n",
    "            response = spot.artists( nuLst )\n",
    "            for artist in response['artists']:\n",
    "                qArtist = artist['id']\n",
    "                data['artists'][ qArtist ]['name'  ] = artist['name'  ]\n",
    "                data['artists'][ qArtist ]['genres'] = artist['genres']\n",
    "            sleep( pause_s )\n",
    "\n",
    "        for qArtist in qArtLs:\n",
    "            for spGenre in data['artists'][ qArtist ]['genres']:\n",
    "                if spGenre not in mainDist:\n",
    "                    mainDist[ spGenre ]  = 1\n",
    "                else:\n",
    "                    mainDist[ spGenre ] += 1\n",
    "\n",
    "    if len( mainDist ):\n",
    "        topSpGenre = sort_keys_by_value( mainDist, reverse = True )[0]\n",
    "    else:\n",
    "        topSpGenre = _NULL_GENRE\n",
    "\n",
    "    genreDct['nameSpot'] = topSpGenre\n",
    "\n",
    "    loclDist = normalize_dist( loclDist )\n",
    "    mainDist = normalize_dist( mainDist )\n",
    "    genreDct['nameDist'] = mainDist\n",
    "\n",
    "    localName = \"\"\n",
    "    namLast   = roll_outcome( mainDist )\n",
    "    if namLast is None:\n",
    "        namLast = \"Music\"\n",
    "        P_last    = 1.0\n",
    "        running   = True\n",
    "    else:\n",
    "        P_last    = max( 0.333, mainDist[ namLast ] )\n",
    "        running   = (random() < P_last)\n",
    "    \n",
    "    localName += Proper_Namify( roll_outcome( loclDist ) ) + '-' + Proper_Namify( namLast )\n",
    "\n",
    "    nPart = 0\n",
    "    while running:\n",
    "        namLast = roll_outcome( loclDist )\n",
    "        P_last  = max( 0.333, loclDist[ namLast ] )\n",
    "        running = random() < min( P_last*10.0, 0.95 )\n",
    "        localName += ' ' + Proper_Namify( namLast ) \n",
    "        nPart += 1\n",
    "        if nPart >= _NAME_PT_LIM:\n",
    "            break\n",
    "\n",
    "    genreDct['nameLocal'] = localName\n",
    "\n",
    "    print( f\"{genreDct['nameLocal']} | {genreDct['nameSpot']} | {genreDct['nameDist']}\" )\n",
    "\n",
    "\n",
    "def generate_genres_from_track_list( tracks ):\n",
    "    \"\"\" Use DBSCAN to generate clusters based on track vectors, Give them names, Then return as a `dict` \"\"\"\n",
    "    # NOTE: This function assumes that `tracks` was built using `fetch_entire_playlist_with_audio_features`                \n",
    "    global data\n",
    "    print( f\"\\n########## Extract genre info from {len(tracks)} tracks! ##########\\n\" )\n",
    "\n",
    "    ### Compute Clusters ###\n",
    "    trkVecs = get_tracks_as_vectors( tracks )\n",
    "    clustrs = DBSCAN( eps = _DBS_EPSILON, min_samples = _DBS_MIN_MMBR ).fit( trkVecs )\n",
    "    genres  = dict()\n",
    "    for i, trk_i in enumerate( tracks ):\n",
    "        lbl_i = clustrs.labels_[i]\n",
    "        if (lbl_i not in genres):\n",
    "            genres[ lbl_i ] = {\n",
    "                'nameSpot' : None, # --- Most prominent Spotify genre across all artists\n",
    "                'nameDist' : None, # --- Discrete distribution of Spotify genre across all artists\n",
    "                'nameLocal': None, # --- Humorous (semi-)unique name given to micro-genre\n",
    "                'tracks'   : [trk_i,], # Tracks that belong to this micro-genre\n",
    "                'len'      : 1, # ------ Number of identified tracks in the micro-genre\n",
    "                'vectors'  : None, # --- Vector representation of the tracks\n",
    "                'origins'  : list(), # Playlist(s) that tracks come from\n",
    "            }\n",
    "        else:\n",
    "            genres[ lbl_i ]['tracks'].append( trk_i )\n",
    "            genres[ lbl_i ]['len'   ] += 1\n",
    "\n",
    "    # Erase outliers\n",
    "    if -1 in genres:\n",
    "        del genres[-1]\n",
    "    print( f\"Identified {len(genres)} genres in this collection of {len(tracks)} tracks!\" )\n",
    "    # Generate unique keys for genres\n",
    "    rtnGenres = dict()\n",
    "    for k, v in genres.items():\n",
    "        rtnGenres[ str( uuid4() ) ] = v\n",
    "\n",
    "    ### Compute Center and kdTree for genre ###\n",
    "    for gnre in rtnGenres.values():\n",
    "        genre_vector_ops( gnre )\n",
    "\n",
    "        # Generate micro-genre names {Spotify, Distribution, Local}\n",
    "        extract_and_generate_genre_names( gnre )\n",
    "    \n",
    "    print( f\"\\n########## Genre extraction COMPLETE! ##########\\n\" )\n",
    "\n",
    "    return rtnGenres\n",
    "\n",
    "\n",
    "def extract_micro_genres_from_collection( eraseExisting = True ):\n",
    "    \"\"\" Extract and merge micro-genres from the entire collection defined by `data` \"\"\"\n",
    "    global data\n",
    "    \n",
    "    if eraseExisting:\n",
    "        data['genres'] = dict()\n",
    "    \n",
    "    for plName_i, playls_i in data['playlists'].items():\n",
    "        print( f\"\\n### Playlist: {plName_i}, {playls_i['ID']} ###\\n\" )\n",
    "        bgn_i    = now()\n",
    "        tracks_i = playls_i['tracks']\n",
    "        N_trks_i = len( tracks_i )\n",
    "        bgn      = 0\n",
    "        end      = 0\n",
    "        while end < N_trks_i:\n",
    "            bgn     = end\n",
    "            end     = min( end+_N_GN_CHUNK, N_trks_i )\n",
    "            print( f\"\\n## Chunk[ {bgn}:{end} ] ##\\n\" )\n",
    "            \n",
    "            gnres_i = generate_genres_from_track_list( tracks_i[ bgn:end ] )\n",
    "            \n",
    "            for gnre_j in gnres_i.values():\n",
    "                gnre_j['origins'] = [playls_i['ID'],]\n",
    "                \n",
    "            data['genres'].update( gnres_i )\n",
    "            check_API_token() # 2024-08-21: This process can take a while on my home machine\n",
    "\n",
    "        # break\n",
    "            \n",
    "        dur_i = now() - bgn_i\n",
    "        print( f\"\\nGenre generation from {plName_i} took {dur_i/60.0} minutes!\\n\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f633bf7-d7a3-4a68-8113-040c08321427",
   "metadata": {},
   "source": [
    "## Micro-Genre Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a8624-245f-4ed3-95d3-17f6f2f5966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "if _REGEN_DBASE:\n",
    "    # cProfile.run(\"extract_micro_genres_from_collection( data )\")\n",
    "    extract_micro_genres_from_collection( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d7ad60-57e7-461a-9c59-e7d1f33dc9f0",
   "metadata": {},
   "source": [
    "## Merge Micro-Genres into Mini-Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2426bd6-7333-4976-ac43-9ac506afa7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_micro_genres_in_db( ):\n",
    "    \"\"\" Attempt to merge similar genres in the `data` \"\"\"\n",
    "    global data\n",
    "    print( f\"########## Attempt to merge similar genres in the music database ##########\" )\n",
    "    \n",
    "    ### Init ###\n",
    "    Ngenres = len( data['genres'] )\n",
    "    IDs     = list()\n",
    "    trees   = list()\n",
    "    pntLsts = list()\n",
    "    \n",
    "    # Gather track vectors\n",
    "    for k, v in data['genres'].items():\n",
    "        IDs.append( k )\n",
    "        trees.append( v['kdTree'] )\n",
    "        pntLsts.append( v['vectors'] )\n",
    "    \n",
    "    ### Search for merge candidates ###\n",
    "    mergeLst = list()\n",
    "    for i, gID_i in enumerate( IDs ):\n",
    "        pts_i = pntLsts[i]\n",
    "        if len( pts_i ) > 1:\n",
    "            for j in range( i+1, Ngenres ):\n",
    "                gID_j = IDs[j]\n",
    "                kdt_j = trees[j]\n",
    "                dif_j = list()\n",
    "                for pnt_k in pts_i:\n",
    "                    dif_j.append( kdt_j.query( pnt_k )[0] )\n",
    "                if (np.mean( dif_j ) < (_DBS_EPSILON/_MRG_D_FACTOR)):\n",
    "                    found = False\n",
    "                    for mrgSet in mergeLst:\n",
    "                        if ((gID_i in mrgSet) or (gID_j in mrgSet)):\n",
    "                            mrgSet.add( gID_i )\n",
    "                            mrgSet.add( gID_j )\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        mergeLst.append( set([gID_i, gID_j,]) )\n",
    "\n",
    "    print( f\"There are {len(mergeLst)} merge jobs to perform!\" )\n",
    "    \n",
    "    ### Perform all merge jobs ###\n",
    "    for mrgJob in mergeLst:\n",
    "        mDct = {\n",
    "            'nameSpot' : None, # --- Most prominent Spotify genre across all artists\n",
    "            'nameDist' : dict(), # --- Discrete distribution of Spotify genre across all artists\n",
    "            'nameLocal': None, # --- Humorous (semi-)unique name given to micro-genre\n",
    "            'tracks'   : list(), # Tracks that belong to this micro-genre\n",
    "            'len'      : 0, # ------ Number of identified tracks in the micro-genre\n",
    "            'vectors'  : None, # --- Vector representation of the tracks\n",
    "            'kdTree'   : None, # --- Spatial tree for 'vectors'\n",
    "            'origins'  : list(), # Playlist(s) that tracks come from\n",
    "        }\n",
    "        namSplt = list()\n",
    "        keys_i = list( mrgJob )\n",
    "        print( \"\\nMerge:\" )\n",
    "        for j, key_ij in enumerate( keys_i ):\n",
    "            if key_ij in data['genres']:\n",
    "                if j > 0:\n",
    "                    print( \"\\t\\t-and-\" )\n",
    "                print( f\"\\t{data['genres'][ key_ij ]['nameLocal']}\" )\n",
    "            \n",
    "        for mID in mrgJob:\n",
    "            if mID in data['genres']:\n",
    "                # Local name components\n",
    "                namSplt.append( [data['genres'][ mID ]['len'], data['genres'][ mID ]['nameLocal'].split(),] )\n",
    "                # Tracks\n",
    "                mDct['tracks'].extend( data['genres'][ mID ]['tracks'] )\n",
    "                # Vectors\n",
    "                if mDct['vectors'] is None:\n",
    "                    mDct['vectors'] = data['genres'][ mID ]['vectors']\n",
    "                else:\n",
    "                    mDct['vectors'] = np.vstack( (mDct['vectors'], data['genres'][ mID ]['vectors'],) )\n",
    "                # Len\n",
    "                mDct['len'] += data['genres'][ mID ]['len']\n",
    "                # Origins\n",
    "                mDct['origins'].extend( data['genres'][ mID ]['origins'] )\n",
    "                # Name Distribution\n",
    "                for k, v in data['genres'][ mID ]['nameDist'].items():\n",
    "                    if k in mDct['nameDist']:\n",
    "                        mDct['nameDist'][k] += v * data['genres'][ mID ]['len']\n",
    "                    else:\n",
    "                        mDct['nameDist'][k]  = v * data['genres'][ mID ]['len']\n",
    "                # Delete the merged genre\n",
    "                del data['genres'][ mID ]\n",
    "        if (mDct['vectors'] is not None) and (len( mDct['vectors'] ) > 1):\n",
    "            # Recalc the spatial tree\n",
    "            mDct['kdTree'] = cKDTree( mDct['vectors'], balanced_tree = False, compact_nodes = False )\n",
    "        # Normalize Name Distribution\n",
    "        mDct['nameDist'] = normalize_dist( mDct['nameDist'] )\n",
    "        # Choose the top Spotify genre\n",
    "        if len( mDct['nameDist'] ):\n",
    "            topSpGenre = sort_keys_by_value( mDct['nameDist'], reverse = True )[0]\n",
    "        else:\n",
    "            topSpGenre = _NULL_GENRE\n",
    "        mDct['nameSpot'] = topSpGenre\n",
    "        \n",
    "        # Construct a new local name\n",
    "        lenLst = [len( item[1] ) for item in namSplt]\n",
    "        if len( lenLst ) > 0:\n",
    "            lenMax = max( lenLst )\n",
    "            lclNam = \"\"\n",
    "            for j in range( lenMax ):\n",
    "                dice = dict()\n",
    "                for k, (mag_k, lst_k) in enumerate( namSplt ):\n",
    "                    # print( f\"Components: {k}, {mag_k}, {lst_k}\" )\n",
    "                    len_k = len( lst_k )\n",
    "                    if j < len_k:\n",
    "                        dice[ lst_k[j] ] = mag_k\n",
    "                token = roll_outcome( dice )\n",
    "                # print( namSplt )\n",
    "                # print( lenLst )\n",
    "                # pprint( dice )\n",
    "                # print( f\"Token: {token}\" )\n",
    "                if j > 0:\n",
    "                    lclNam += ' '\n",
    "                lclNam += (token if (token is not None) else _NULL_GENRE)\n",
    "            mDct['nameLocal'] = lclNam\n",
    "        else:\n",
    "            mDct['nameLocal'] = _NULL_GENRE\n",
    "\n",
    "        # Store the merged mini-genre\n",
    "        nuID = str( uuid4() )\n",
    "        data['genres'][ nuID ] = mDct\n",
    "        print( f\"Merge Complete!: New Mini-Genre {mDct['nameLocal']} ({nuID}) created with {mDct['len']} tracks!\" )\n",
    "\n",
    "\n",
    "def move_mini_genre_outliers_to_better_homes( ):\n",
    "    \"\"\" Attempt to rehome outlier tracks that were collected during the micro-genre creation and merge \"\"\"\n",
    "    global data\n",
    "    \n",
    "    ### Search for split candidates ###\n",
    "    Ngenres = len( data['genres'] )\n",
    "    IDs     = list()\n",
    "    trees   = list()\n",
    "    pntLsts = list()\n",
    "    dstLsts = list()\n",
    "\n",
    "    # Gather track vectors\n",
    "    for k, v in data['genres'].items():\n",
    "        IDs.append( k )\n",
    "        trees.append( v['kdTree'] )\n",
    "        pntLsts.append( v['vectors'] )\n",
    "\n",
    "    # Evaluate spread within each mini-genre\n",
    "    for i, pts_i in enumerate( pntLsts ):\n",
    "        avgDist = list()\n",
    "        if pts_i is not None:\n",
    "            for j, pnt_j in enumerate( pts_i ):\n",
    "                dists = list()\n",
    "                for k, pnt_k in enumerate( pts_i ):\n",
    "                    dists.append( np.linalg.norm( np.subtract( pnt_j, pnt_k ) ) )\n",
    "                avgDist.append( np.mean( dists ) )\n",
    "            dstLsts.append( avgDist )\n",
    "        else:\n",
    "            dstLsts.append( _ONE_BILLION )\n",
    "\n",
    "    ## Evaluate relative closeness of every point in a genre to every other genre ##\n",
    "    # For every mini-genre, do\n",
    "    for i, gID_i in enumerate( IDs ):\n",
    "        if pntLsts[i] is None:\n",
    "            continue\n",
    "        pts_i = pntLsts[i][:].tolist()\n",
    "        dst_i = dstLsts[i][:]\n",
    "        # For every vector in the mini-genre, do\n",
    "        j = 0 \n",
    "        while (j < len( pts_i )):\n",
    "            pnt_j = pts_i[j]\n",
    "            dst_j = dst_i[j]\n",
    "            dMn_j = 1e6\n",
    "            gnr_j = None\n",
    "            # For every other mini-genre, Search for the shortest dist\n",
    "            for k, gID_k in enumerate( IDs ):\n",
    "                if i != k:\n",
    "                    tre_k  = data['genres'][ gID_k ]['kdTree']\n",
    "                    if tre_k is not None:\n",
    "                        dst_jk = tre_k.query( pnt_j )[0]\n",
    "                        if ((dst_jk < dst_j) and (dst_jk < dMn_j)):\n",
    "                            dMn_j = dst_jk\n",
    "                            gnr_j = gID_k\n",
    "            # If a new home was found, then move\n",
    "            if gnr_j is not None:\n",
    "                print( f\"Moving track {j} of  {data['genres'][ gID_i ]['nameLocal']}  --to->  {data['genres'][ gnr_j ]['nameLocal']}\" )\n",
    "                trk_j = data['genres'][ gID_i ]['tracks'][j]\n",
    "                data['genres'][ gID_i ]['tracks'].pop(j)\n",
    "                pts_i.pop(j)\n",
    "                dst_i.pop(j)\n",
    "                data['genres'][ gnr_j ]['tracks'].append( trk_j )\n",
    "                data['genres'][ gnr_j ]['changed'] = True\n",
    "                data['genres'][ gID_i ]['changed'] = True\n",
    "            else:\n",
    "                j += 1\n",
    "                \n",
    "    # For every mini-genre, Recalc vectors if it has changed\n",
    "    for i, gID_i in enumerate( IDs ):\n",
    "        genre_vector_ops( data['genres'][ gID_i ] )\n",
    "        data['genres'][ gID_i ]['changed'] = False\n",
    "            \n",
    "\n",
    "    print( \"\\n########## Genre Report ##########\\n\" )\n",
    "    print( f\"Filter {len( data['genres'] )} to filter...\\n\" )\n",
    "    lstDel = list()\n",
    "    \n",
    "    for gID, genre in data['genres'].items():\n",
    "        if genre['len'] >= _MIN_GNR_MMBR:\n",
    "            print( f\"{genre['nameLocal']}, {genre['len']}\" )\n",
    "        else:\n",
    "            lstDel.append( gID )\n",
    "\n",
    "    print( \"Deleting ...\", end = \" \" )\n",
    "    for gID in lstDel:\n",
    "        print( gID, end = \", \" )\n",
    "        del data['genres'][ gID ]\n",
    "        \n",
    "    print( f\"\\nDeleted {len( lstDel )} mini-genres, {len( data['genres'] )} remain\" )\n",
    "    print( \"\\n########## Report Complete ##########\\n\" )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a60c8f-0ee6-4ca5-95d5-97fb5d393a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _REGEN_DBASE:\n",
    "    merge_micro_genres_in_db( )\n",
    "    move_mini_genre_outliers_to_better_homes( )\n",
    "    save_music_database( data, outPath )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799d31b-8ab0-4e1d-95c3-888f18570ffb",
   "metadata": {},
   "source": [
    "# Search Version 02, Graded by Mini-Genre Proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42daba72-589f-452e-8818-da2ed265feb9",
   "metadata": {},
   "source": [
    "## Sub-Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac966fac-f0b1-4f17-baff-5feccf44a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tracks_from_new_releases( N, div = 12, pause_s = 0.25 ):\n",
    "    \"\"\" Get `N` tracks from newly-released albums \"\"\"\n",
    "    global data\n",
    "    \n",
    "    totTrks = list()\n",
    "    Nalbums = int( ceil( N / div ) )\n",
    "    albOfst =  0\n",
    "    count   =  0\n",
    "    Niter   =  0\n",
    "    itrLim  = 20\n",
    "\n",
    "    while count < N: \n",
    "\n",
    "        Niter += 1\n",
    "\n",
    "        if Niter > itrLim:\n",
    "            break\n",
    "        \n",
    "        if data is not None:\n",
    "            if _NU_REL_Q_KEY in data['queries']:\n",
    "                albOfst = data['queries'][ _NU_REL_Q_KEY ]\n",
    "                data['queries'][ _NU_REL_Q_KEY ] += Nalbums\n",
    "            else:\n",
    "                data['queries'][ _NU_REL_Q_KEY ] = Nalbums\n",
    "        \n",
    "        response = spot.new_releases( limit = Nalbums, offset = albOfst )\n",
    "        nuAlbums = [item['id'] for item in response['albums']['items']]\n",
    "        sleep( pause_s )\n",
    "        \n",
    "        for albumID in nuAlbums:\n",
    "            res    = spot.album_tracks( albumID, limit = 50, offset = 0 )\n",
    "            tracks = res['items']\n",
    "            totTrks.extend( tracks )\n",
    "            count += len( tracks )\n",
    "            sleep( pause_s )\n",
    "\n",
    "    return totTrks\n",
    "\n",
    "\n",
    "def get_recommended_tracks_from_db( N_tracks, pause_s = 0.25 ):\n",
    "    \"\"\" Recommended tracks by both artists and genres \"\"\"\n",
    "    global data\n",
    "    count  = 0\n",
    "    gIDs   = list( data['genres'].keys() )\n",
    "    rtnLst = list()\n",
    "    while count < N_tracks:\n",
    "        recArt = list()\n",
    "        recTrk = list()\n",
    "        recGnr = list()\n",
    "        gID    = choice( gIDs )\n",
    "        gnre   = data['genres'][ gID ]\n",
    "        for i in range( 5 ):\n",
    "            trk_i = choice( gnre['tracks'] )\n",
    "            art_i = choice( trk_i['track']['album']['artists'] )\n",
    "            if i % 3 == 0:\n",
    "                recArt.append( art_i['id'] )\n",
    "            elif i % 2 == 0:    \n",
    "                recTrk.append( trk_i['track']['id'] )\n",
    "            else:\n",
    "                recGnr.append( roll_outcome( gnre['nameDist'] ) )\n",
    "                \n",
    "        nFetch = min( _RESPONSE_LIMIT, max( N_tracks-count, 0 ) )\n",
    "        if nFetch > 0:\n",
    "            response = spot.recommendations(\n",
    "                seed_artists = recArt, \n",
    "                seed_genres  = recGnr, \n",
    "                seed_tracks  = recTrk, \n",
    "                limit        = nFetch\n",
    "            )\n",
    "            sleep( pause_s )\n",
    "            # pprint( response )\n",
    "            tracks = response['tracks']\n",
    "            count += len( tracks )\n",
    "            rtnLst.extend( tracks )\n",
    "        else:\n",
    "            break\n",
    "    return rtnLst\n",
    "        \n",
    "\n",
    "def get_tracks_from_related_artists( N_tracks, pause_s = 0.25 ):\n",
    "    \"\"\" Attempt to get fresh tracks from Spotify given artists currently in the collection \"\"\"\n",
    "    global data\n",
    "    skipN  = 5\n",
    "    count  = 0\n",
    "    plNam  = list( data['playlists'].keys() )\n",
    "    rtnLst = list()\n",
    "\n",
    "    while count < N_tracks:\n",
    "        tracks = data['playlists'][ choice( plNam ) ]['tracks']\n",
    "        artist = choice( choice( tracks )['track']['album']['artists'] )['id']\n",
    "        res    = spot.artist_related_artists( artist )\n",
    "        artLst = [item['id'] for item in res['artists']]\n",
    "        Nart   = len( artLst )\n",
    "        sleep( pause_s )\n",
    "\n",
    "        # For each artist, Get top tracks\n",
    "        for art_i in artLst:\n",
    "            qArtist = _ART_Q_PREFIX + str( art_i )\n",
    "            if qArtist not in data['queries']:\n",
    "                res = spot.artist_top_tracks( art_i )\n",
    "                sleep( pause_s )\n",
    "                count += len( res['tracks'] )\n",
    "                rtnLst.extend( res['tracks'] )\n",
    "                data['queries'][ qArtist ] = 1\n",
    "\n",
    "        # For each group of artists, Get recommendations\n",
    "        bgn  = 0\n",
    "        end  = 0\n",
    "        grps = list()\n",
    "        while end < Nart:\n",
    "            bgn = end\n",
    "            end = min( end+skipN, Nart )\n",
    "            grps.append( artLst[ bgn:end ] )\n",
    "        for artGrp in grps:\n",
    "            nFetch = min( _RESPONSE_LIMIT, max( N_tracks-count, 0 ) )\n",
    "            if nFetch > 0:\n",
    "                response = spot.recommendations(\n",
    "                    seed_artists = artGrp, \n",
    "                    limit        = nFetch\n",
    "                )\n",
    "                sleep( pause_s )\n",
    "                # pprint( response )\n",
    "                tracks = response['tracks']\n",
    "                count += len( tracks )\n",
    "                rtnLst.extend( tracks )\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return rtnLst\n",
    "\n",
    "\n",
    "def get_tracks_from_featured_playlists( N_tracks, pause_s = 0.25 ):\n",
    "    \"\"\" Attempt to get fresh tracks from Spotify featured playlists, one at a time \"\"\"\n",
    "    global data\n",
    "    step    = 1\n",
    "    count   = 0\n",
    "    totTrks = list()\n",
    "    while count < N_tracks:\n",
    "        ofst  = data['queries'][ _FEAT_PL_Q_KY ] if (_FEAT_PL_Q_KY in data['queries']) else 0\n",
    "        data['queries'][ _FEAT_PL_Q_KY ] = data['queries'].get( _FEAT_PL_Q_KY, 0 ) + 1\n",
    "        response = spot.featured_playlists( limit = step, offset = ofst )\n",
    "        if len( response['playlists']['items'] ):\n",
    "            plylstID = response['playlists']['items'][0]['id']\n",
    "            tracks   =  fetch_entire_playlist_with_audio_features( plylstID )\n",
    "            count   += len( tracks )\n",
    "            totTrks.extend( tracks )\n",
    "    return totTrks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58927d9-775a-4b73-9c6e-1bfd3363c0a6",
   "metadata": {},
   "source": [
    "## Search and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483804f4-cd20-4b5e-8065-4f8c6f12594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShuffleSoGood import get_track_vector, _MIN_LEN_S\n",
    "\n",
    "def add_audio_features_to_track_list( tracks, pause_s = 0.25 ):\n",
    "    \"\"\" Add audio features and calc vector for all `tracks` \"\"\"\n",
    "    ## Init ##\n",
    "    N_trks = len( tracks )\n",
    "    featrs = list()\n",
    "    rtnLst = list()\n",
    "\n",
    "    if N_trks:\n",
    "    \n",
    "        bgn    = 0\n",
    "        end    = 0\n",
    "        \n",
    "        ## Get Features ##\n",
    "        while end < N_trks:\n",
    "            bgn = end\n",
    "            end = min( end+_RESPONSE_LIMIT, N_trks )\n",
    "            # pprint( tracks[0] )\n",
    "            lst = [item['id'] for item in tracks[ bgn:end ]]\n",
    "            featrs.extend( spot.audio_features( lst ) )\n",
    "            sleep( pause_s )\n",
    "    \n",
    "            \n",
    "        ## Add Features and Vectors ##\n",
    "        for i, track_i in enumerate( tracks ):\n",
    "            updat_i = featrs[i]\n",
    "            if updat_i is not None:\n",
    "                track_i.update( updat_i )\n",
    "                track_i['vector'] = get_track_vector( track_i )\n",
    "            rtnLst.append( track_i )\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def filter_short_and_explicit_tracks( qTracks ):\n",
    "    \"\"\" Remove short (<1:45) and explicit (guaranteed vocal) songs and Return filtered tracks \"\"\"\n",
    "    tracks = qTracks[:]\n",
    "    # 3. For every track j in playlist, do\n",
    "    j = 0\n",
    "    while j < len( tracks ):\n",
    "        track_j   = tracks[j]\n",
    "        trackID_j = track_j['id']\n",
    "        len_s_j   = track_j['duration_ms']/1000.0\n",
    "        explc_j   = track_j.get( 'explicit', False )\n",
    "\n",
    "        if ((len_s_j < _MIN_LEN_S) or explc_j):\n",
    "            tracks.pop(j)\n",
    "        else:\n",
    "            j += 1\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def filter_collected_and_reviewed_tracks( qTracks ):\n",
    "    \"\"\" Remove songs that are either already in the collection or have been reviewed and Return filtered tracks \"\"\"\n",
    "    global data\n",
    "    tracks = qTracks[:]\n",
    "    trkSet = set([])\n",
    "    # 3. For every track j in playlist, do\n",
    "    j = 0\n",
    "    while j < len( tracks ):\n",
    "        track_j   = tracks[j]\n",
    "        trackID_j = track_j['id']\n",
    "        p_collect = (trackID_j in data['collectID'])\n",
    "        p_reviewd = (trackID_j in data['reviewID' ])\n",
    "        p_intake  = (trackID_j in trkSet)\n",
    "\n",
    "        if (p_collect or p_reviewd or p_intake):\n",
    "            tracks.pop(j)\n",
    "        else:\n",
    "            trkSet.add( trackID_j )\n",
    "            j += 1\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def guided_multi_search_version_02( N_tracks ):\n",
    "    global data\n",
    "    print( \"\\n########## Guided Multi-Search, Version_02 ##########\\n\" )\n",
    "    \n",
    "    ### Search && Gather ###\n",
    "    print( f\"Search for {N_tracks} new releases ...\" )\n",
    "    tracks = get_tracks_from_new_releases( N_tracks, div = 12,  pause_s = 0.25 )\n",
    "    # pprint( tracks[-1] )\n",
    "    \n",
    "    print( f\"Search for {N_tracks} recommendations ...\" )\n",
    "    tracks.extend( get_recommended_tracks_from_db( N_tracks, pause_s = 0.25 ) )\n",
    "    # pprint( tracks[-1] )\n",
    "    \n",
    "    print( f\"Search for {N_tracks} tracks from artists similar to collection ...\" )\n",
    "    tracks.extend( get_tracks_from_related_artists( N_tracks, pause_s = 0.25 ) )\n",
    "    # pprint( tracks[-1] )\n",
    "    \n",
    "    print( f\"Search for {N_tracks} tracks in Spotify featured playlists ...\" )\n",
    "    tracks.extend( get_tracks_from_featured_playlists( N_tracks, pause_s = 0.25 ) )\n",
    "    # pprint( tracks[-1] )\n",
    "    \n",
    "    print( f\"Search for {N_tracks} tracks using Version 01 ...\" )\n",
    "    tracks.extend( basic_new_music_search_01( N_tracks, Mper = 5, pause_s = 0.125 ) )\n",
    "    # pprint( tracks[-1] )\n",
    "    \n",
    "    print( f\"Multi-Search COMPLETE: Retreived {len(tracks)} tracks!\\n\" )\n",
    "\n",
    "    ### Filter ###\n",
    "    print( f\"About to filter {len(tracks)} tracks ...\" )\n",
    "    \n",
    "    # for i in range( 0, int(N_tracks/2), len(tracks) ):\n",
    "    #     print( f\"\\n\\n Track {i}:\" )\n",
    "    #     pprint( tracks[i] )\n",
    "        \n",
    "    tracks = add_audio_features_to_track_list( tracks, pause_s = 0.25 )\n",
    "    \n",
    "    tracks = filter_short_and_explicit_tracks( tracks )\n",
    "    tracks = filter_collected_and_reviewed_tracks( tracks )\n",
    "    \n",
    "    ### Rank by Ascending Distance to Nearest Mini-Genre ###\n",
    "    print( f\"About to rank {len(tracks)} tracks ...\" )\n",
    "    for trk_i in tracks:\n",
    "        dMin_i = _ONE_BILLION\n",
    "        gnre_i = _NULL_GENRE\n",
    "        for gnID_j, mGenre_j in data['genres'].items():\n",
    "            dist_j = mGenre_j['kdTree'].query( trk_i['vector'] )[0]\n",
    "            if dist_j < dMin_i:\n",
    "                dMin_i = dist_j\n",
    "                gnre_i = gnID_j\n",
    "        trk_i['minGenreDist' ] = dMin_i\n",
    "        trk_i['mini-genre_ID'] = gnre_i\n",
    "    tracks.sort( key = lambda item: item['minGenreDist'] )\n",
    "    print( \"\\n########## Multi-Search 02: COMPLETE ##########\\n\" )\n",
    "\n",
    "    ### Return Top Hits ###\n",
    "    if len( tracks ) < N_tracks:\n",
    "        return tracks\n",
    "    else:\n",
    "        return tracks[ :N_tracks ]\n",
    "\n",
    "\n",
    "def refill_playlist_with_new_tracks_02( plID, Ntot = _N_BACKFILL, pause_s = 0.50 ):\n",
    "    \"\"\" Top off the playlist with new tracks \"\"\"\n",
    "    global data, outPath\n",
    "    plLen = get_playlist_length( plID )\n",
    "    if Ntot > plLen:\n",
    "        nRem = Ntot - plLen\n",
    "        print( f\"About to add {nRem} tracks ...\" )\n",
    "        addTrks = guided_multi_search_version_02( nRem )\n",
    "        addID   = [item['id'] for item in addTrks]\n",
    "        Nadd    = len( addID )\n",
    "        bgn     = 0\n",
    "        end     = 0\n",
    "        while end < Nadd:\n",
    "            bgn    = end\n",
    "            end    = min( end+_RESPONSE_LIMIT, Nadd )\n",
    "            result = spot.user_playlist_add_tracks( CLIENT_ID, plID, addID[ bgn:end ] )\n",
    "        save_music_database( data, outPath ) # Save queries we made\n",
    "        print( \"Playlist refill complete!\" )\n",
    "    else:\n",
    "        print( \"No room for new tracks!\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85378767-2f61-45da-ab3f-900e1fa0599e",
   "metadata": {},
   "source": [
    "# Genre Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf491a90-32a0-47a1-aa03-ad8a97374102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "def set_genre_membership( ):\n",
    "    \"\"\" Make sure all genres have a membership ID hash \"\"\"\n",
    "    global data\n",
    "    for gnreID_k, genre_k in data['genres'].items():\n",
    "        if ('trackIDs' not in genre_k):\n",
    "            genre_k['trackIDs'] = set([])\n",
    "        for l, track_l in enumerate( genre_k['tracks'] ):\n",
    "            genre_k['trackIDs'].add( track_l['id'] )\n",
    "    \n",
    "\n",
    "def get_homeless_tracks( ):\n",
    "    \"\"\" Return a list of tracks not assicated with a current mini-genre \"\"\"\n",
    "    global data\n",
    "    set_genre_membership( )\n",
    "    rtnLst = list()\n",
    "    for plName_i, playls_i in data['playlists'].items():\n",
    "        for j, track_j in enumerate( playls_i['tracks'] ):\n",
    "            found   = False\n",
    "            trkID_j = track_j['id']\n",
    "            for gnreID_k, genre_k in data['genres'].items():\n",
    "                if trkID_j in genre_k['trackIDs']:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                rtnLst.append( track_j )\n",
    "    shuffle( rtnLst )\n",
    "    print( f\"Found {len(rtnLst)} unaffiliated tracks!\" )\n",
    "    return rtnLst\n",
    "\n",
    "\n",
    "def genretize_remainder( chunkSize = _N_RM_CHUNK ):\n",
    "    \"\"\" Try to generate affliations for free tracks \"\"\"\n",
    "    global data\n",
    "    freeTrks = get_homeless_tracks( )\n",
    "    NfreTrks = len( freeTrks )\n",
    "    \n",
    "    bgn      = 0\n",
    "    end      = 0\n",
    "    trkChnks = list()\n",
    "    while end < NfreTrks:\n",
    "        bgn = end\n",
    "        end = min( end+chunkSize, NfreTrks )\n",
    "        trkChnks.append( freeTrks[ bgn:end ] )\n",
    "\n",
    "    for i, tracks_i in enumerate( trkChnks ):\n",
    "        bgn_i    = now()\n",
    "        gnres_i  = generate_genres_from_track_list( tracks_i )\n",
    "        for gnre_j in gnres_i.values():\n",
    "            gnre_j['origins'] = ['FreeTracks',]\n",
    "        data['genres'].update( gnres_i )\n",
    "        dur_i = now() - bgn_i\n",
    "        print( f\"\\nGenre generation from {len(tracks_i)} tracks took {dur_i/60.0} minutes!\\n\" )\n",
    "        check_API_token() # 2024-08-21: This process can take a while on my home machine\n",
    "\n",
    "\n",
    "def recruit_remainder( ):\n",
    "    \"\"\" Attempt to move free tracks to already-generated mini-genres \"\"\"\n",
    "    global data\n",
    "    freeTrks = get_homeless_tracks( )\n",
    "    NfreTrks = len( freeTrks )\n",
    "    totCount = 0\n",
    "\n",
    "    def membership_score( qPnt, kNNpts ):\n",
    "        \"\"\" Return a score that expresses cluster membership, Higher is better, -1 means not a member \"\"\"\n",
    "        if (len(kNNpts) < _DBS_MIN_MMBR):\n",
    "            return -1\n",
    "        dists = sorted( [item[0] for item in kNNpts] )\n",
    "        insid = 0\n",
    "        score = 0\n",
    "        for i, p_i in enumerate( kNNpts ):\n",
    "            d_i    = np.linalg.norm( np.subtract( qPnt, p_i ) )\n",
    "            score += np.exp( -d_i ) # The closer it is, the larger this number    \n",
    "        return score\n",
    "\n",
    "    for i, track_i in enumerate( freeTrks ):\n",
    "        if (i%100==0):\n",
    "            print( '.', end='', flush=1 )\n",
    "        hiScore = -1\n",
    "        hiGenre = None\n",
    "        \n",
    "        for gnreID_j, genre_j in data['genres'].items():\n",
    "            nn_j = genre_j['kdTree'].query_ball_point( track_i['vector'], _DBS_EPSILON )\n",
    "            nn_j = [genre_j['vectors'][ index ] for index in nn_j]\n",
    "            sc_j = membership_score( track_i['vector'], nn_j )\n",
    "            if sc_j > hiScore:\n",
    "                hiScore = sc_j\n",
    "                hiGenre = gnreID_j\n",
    "                \n",
    "        if (hiGenre is not None):\n",
    "            data['genres'][ hiGenre ]['tracks' ].append( track_i )\n",
    "            data['genres'][ hiGenre ]['changed'] = True\n",
    "            totCount += 1\n",
    "    print()\n",
    "\n",
    "    for gnre in data['genres'].values():         \n",
    "        if gnre.get( 'changed', False ):\n",
    "            print( f\"Recalculating  {gnre['nameLocal']}  ...\" )\n",
    "            genre_vector_ops( gnre )\n",
    "            gnre['changed'] = False\n",
    "\n",
    "    set_genre_membership()\n",
    "    print( f\"Found homes for {totCount} free tracks!\" )\n",
    "    get_homeless_tracks()\n",
    "\n",
    "\n",
    "def populate_releases( ):\n",
    "    \"\"\" Make sure releases are populated \"\"\"\n",
    "    global data\n",
    "    print( type( data ) )\n",
    "    for plName_i, plyLst_i in data['playlists'].items():\n",
    "        print( plName_i, '-', plyLst_i['ID'], '...' )\n",
    "        tracks_i = plyLst_i['tracks']\n",
    "        assign_vectors_to_tracks( tracks_i )\n",
    "\n",
    "        # Catalog artists from collection tracks (Req'd for (Sub-)Search 01)\n",
    "        for track_j in tracks_i:\n",
    "            for artist_k in track_j['track']['artists']:\n",
    "                artistID_j = artist_k['id']\n",
    "                if artistID_j not in data['artists']:\n",
    "                    data['artists'][ artistID_j ] = { \n",
    "                        'name'    : track_j['track']['artists'][0]['name'], \n",
    "                        'count'   : 1, \n",
    "                        'releases': [track_j['track']['album']['release_date'],], \n",
    "                    }\n",
    "                else:\n",
    "                    data['artists'][ artistID_j ]['count'   ] += 1\n",
    "                    data['artists'][ artistID_j ]['releases'].append( track_j['track']['album']['release_date'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7d3b2-a6d1-468a-a21c-1768601447e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _REGEN_DBASE:\n",
    "    genretize_remainder( chunkSize = _N_RM_CHUNK )\n",
    "    merge_micro_genres_in_db( )\n",
    "    move_mini_genre_outliers_to_better_homes( )\n",
    "    recruit_remainder(  )\n",
    "    save_music_database( data, outPath ) # Save queries we made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e0bc5-ab0f-4217-ad3f-77546c7cdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _SEARCH_BKFL:\n",
    "    check_API_token()\n",
    "    populate_releases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19c396-cd1e-48dc-b35a-ab72413e90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _SEARCH_BKFL:\n",
    "    check_API_token()\n",
    "    refill_playlist_with_new_tracks_02( _FILL_PL_ID, Ntot = _N_BACKFILL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081ced5-e1f2-4669-9685-b16b08a29951",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _SEARCH_BKFL:\n",
    "    save_music_database( data, outPath ) # Save queries we made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69403fb-9d7f-41d6-99ba-8ff782c44baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
