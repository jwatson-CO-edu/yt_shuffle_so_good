{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030cd40b-d9dc-4e62-8944-5f928497aef0",
   "metadata": {},
   "source": [
    "`python3.11 -m pip install jupyterlab PyEnchant scipy numpy spotipy scikit-learn --user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f39117-48a7-4c24-8e7d-7a7c561bb53e",
   "metadata": {},
   "source": [
    "# Init & Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021216f0-751d-42c6-a049-0166f0eea696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pickle, os\n",
    "now = time.time\n",
    "from math import ceil\n",
    "from random import randrange, choice, random\n",
    "from time import sleep\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import enchant\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "## Client Info ##\n",
    "CLIENT_ID     = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "CLIENT_SCOPE  = \"user-follow-modify playlist-modify-private playlist-modify-public\"\n",
    "USER_NAME     = \"31ytgsr7wdmiaroy77msqpiupdsi\"\n",
    "REDIR_URI     = \"https://github.com/jwatson-CO-edu/yt_shuffle_so_good\"\n",
    "AUTH_URL      = 'https://accounts.spotify.com/api/token'\n",
    "BASE_URL      = 'https://api.spotify.com/v1/'\n",
    "\n",
    "## API Info ##\n",
    "_RESPONSE_LIMIT =  100\n",
    "_ARTIST_Q_LIM   =   50\n",
    "_MAX_OFFSET     = 1000\n",
    "_T_LOGIN_S      = 60.0 * 10 #20 # 25 # 50\n",
    "tLastAuth       = 0.0\n",
    "\n",
    "with open( \"../keys/spot_ID.txt\" , 'r' ) as f:\n",
    "    CLIENT_ID = f.readlines()[0].strip()\n",
    "\n",
    "with open( \"../keys/spot_SECRET.txt\" , 'r' ) as f:\n",
    "    CLIENT_SECRET = f.readlines()[0].strip()\n",
    "\n",
    "token = None\n",
    "spot  = None\n",
    "\n",
    "\n",
    "def check_API_token():\n",
    "    global tLastAuth, token, _T_LOGIN_S, spot\n",
    "    tNow    = now()\n",
    "    elapsed = tNow - tLastAuth\n",
    "    if elapsed >= _T_LOGIN_S:\n",
    "        token = util.prompt_for_user_token(\n",
    "            username      = USER_NAME,\n",
    "            scope         = CLIENT_SCOPE,\n",
    "            client_id     = CLIENT_ID,\n",
    "            client_secret = CLIENT_SECRET,\n",
    "            redirect_uri  = REDIR_URI\n",
    "        )\n",
    "        spot = spotipy.Spotify( auth = token )\n",
    "        print( token )\n",
    "        clear_output( wait = True )\n",
    "        sleep( 2 )\n",
    "        print( \"TOKEN OBTAINED\" )\n",
    "        tLastAuth = tNow\n",
    "    else:\n",
    "        print( f\"TOKEN STILL VALID, AGE: {elapsed/60.0} MINUTES\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643e4861-2fed-44bf-81d0-53af493d8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN OBTAINED\n"
     ]
    }
   ],
   "source": [
    "check_API_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d1583-abb2-4c30-af15-f43082b839ee",
   "metadata": {},
   "source": [
    "## Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ad3b37-1ec4-474d-adfc-fcad78f6f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "playlist = {\n",
    "    'study01' : \"0a2qoe6S7lYeZ6nlhZdA0v\",\n",
    "    'study02' : \"6gbtR2cBq5PvkghidCvvGk\",\n",
    "    'study03' : \"3o3lN2qntdEV7UKTuuC77K\",\n",
    "    'study04' : \"41sFSisljvBDMBXtpp5NIw\",\n",
    "    'study05' : \"02iS5AFGp8YVuUUqcQf8ys\",\n",
    "    'study06' : \"6KI7A4MWrSM7EyKRUjxIi1\",\n",
    "    'study07' : \"3V055Md2JdrUT8tX0af7di\",\n",
    "    'study08' : \"0tspdJlwSgiyf2O9PO6QaP\",\n",
    "    'study09' : \"5mHRBFoQtYy2izeZ66pG95\",\n",
    "    'study10' : \"3832xeKGEOAXFJqE4K8kIq\",\n",
    "    'study11' : \"65MXR4dubPL9t0P4dgTWvn\",\n",
    "    'study12' : \"0ecSAfnD4CulIVnLt26ukI\",\n",
    "    'study13' : \"7K9ucByFRgDuZk8KMHeJkL\",\n",
    "}\n",
    "\n",
    "review = {\n",
    "    'zd_Over' : \"0v26bHydUxcGC5EbMlkjzG\",\n",
    "    'ze_Over' : \"6SqlfurCBP7eeMOojaDNtS\",\n",
    "    'zf_Over' : \"5TtKaKCouyJp7Hhtu4YlYm\",\n",
    "}\n",
    "\n",
    "backfill = review['zd_Over']\n",
    "_N_BKFL  = 400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857e3ff-a087-4b18-933b-58398c97b3c6",
   "metadata": {},
   "source": [
    "## Session Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286a1d0-44c5-4e62-806b-92cc25990484",
   "metadata": {},
   "source": [
    "* FILTER TYPES: {'album', 'artist', 'track', 'year', 'upc', 'tag:hipster', 'tag:new', 'isrc', 'genre',}\n",
    "* SEARCH TYPES: {\"album\", \"artist\", \"playlist\", \"track\", \"show\", \"episode\", \"audiobook\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc80895-221f-454c-9595-448136e21407",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Session Database Params #####\n",
    "_MOD_T_DAY_S  = 60.0 * 60 * 24\n",
    "_STALE_TIME_S = _MOD_T_DAY_S * 31\n",
    "_MIN_LEN_S    = 60.0 + 45.0\n",
    "_DATA_DIR     = \"data/\"\n",
    "_DATA_PREFIX  = \"Study-Music-Data_\"\n",
    "_DATA_POSTFIX = \".pkl\"\n",
    "_NULL_GENRE   = \"Music\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13120a9-81f1-4e7a-a86e-ee7112d4247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Init Session Database #####\n",
    "data = {\n",
    "    'time'     : now()  , # Data Structure Creation Time\n",
    "    'playlists': dict() , # Study Playlist Info\n",
    "    'collectID': set([]), # Currently accepted track IDs\n",
    "    'review'   : dict() , # Review Playlist Info\n",
    "    'reviewID' : set([]), # Previously reviewed track IDs\n",
    "    'artists'  : dict() , # Study Artist Info\n",
    "    'queries'  : dict() , # Queries made during music searches\n",
    "    'genres'   : dict() , # Study Genre Info\n",
    "    # 2024-08-11: Track info does NOT contain play count\n",
    "}\n",
    "# Pre-emptively Name Session File #\n",
    "timestamp = datetime.now().strftime( '%Y-%m-%dT%H:%M:%S' )\n",
    "outFilNam = _DATA_PREFIX + timestamp + _DATA_POSTFIX\n",
    "outPath   = os.path.join( 'data/', outFilNam )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5d090-4c12-4c71-b203-db3f04ff3aaf",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dad2c0-697c-4260-8803-e169f90bcce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Search 01 Params ##\n",
    "_N_MAX_SEARCH = 50\n",
    "_N_DEF_SEARCH = 10\n",
    "_YEAR_PADDING =  5\n",
    "\n",
    "## DBSCAN Params ##\n",
    "_DBS_EPSILON  =  0.400 # 0.200 # 0.300 # 0.400 # 0.500 # 0.750\n",
    "_DBS_MIN_MMBR =  2\n",
    "\n",
    "## Mini-Genre Params ##\n",
    "_MRG_D_FACTOR =  1.5 # 1.0 # 2.0 #3.0\n",
    "_MIN_GNR_MMBR = 15\n",
    "_ONE_BILLION  = 1e9\n",
    "\n",
    "## Query History Keys ##\n",
    "_NU_REL_Q_KEY = \"NewReleases:Albums\" # Query Key for New Releases\n",
    "_FEAT_PL_Q_KY = \"Featured:Playlists\" # Query Key for Featured Playlists\n",
    "_ART_Q_PREFIX = \"ArtistTopTracks:\" # - Query Key Prefix for Artist Top Tracks\n",
    "\n",
    "## Vector Representation ##\n",
    "_V_NUM_FEATURES  = 10\n",
    "_V_SPEECH_FACTOR =  (1.0/0.3724) * (2.0/3.0) * 5.0\n",
    "_V_INSTR_FACTOR  =  1.0 * 5.0\n",
    "_V_ACOUST_FACTOR =  1.0\n",
    "_V_DANCE_FACTOR  =  1.0 /  0.8701\n",
    "_V_DURATN_FACTOR =  1.0 / 1000.0 / _MIN_LEN_S / 18.7821619\n",
    "_V_ENERGY_FACTOR =  1.0\n",
    "_V_LIVENS_FACTOR =  1.0 /   0.9173\n",
    "_V_LOUDNS_FACTOR =  1.0 /  38.53\n",
    "_V_TEMPO_FACTOR  =  1.0 / (174.331-45.7) * (3.0/4.0) * 3.0\n",
    "_V_VALENC_FACTOR =  1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ed8f73-8f9e-42d4-bac8-a346ac74c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_SKIP_GENRE_BUILD = False\n",
    "_SKIP_GENRE_MERGE = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ffb0b-076d-4a9b-b61b-3edd6eaf453d",
   "metadata": {},
   "source": [
    "# Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af00a3ed-82a6-4b77-b686-fbfda053a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_playlist_length( playlist_ID ):\n",
    "    \"\"\" Get the number of total tracks in the playlist \"\"\"\n",
    "    response = spot.user_playlist_tracks(\n",
    "        CLIENT_ID, \n",
    "        playlist_ID, \n",
    "        fields = 'items,uri,name,id,total', \n",
    "        limit  = _RESPONSE_LIMIT\n",
    "    )\n",
    "    return response['total']\n",
    "    \n",
    "\n",
    "def fetch_entire_playlist( playlist_ID ):\n",
    "    \"\"\" Get infodump on all plalist tracks \"\"\"\n",
    "    plTracks = []\n",
    "    trCount  = 0\n",
    "    response = spot.user_playlist_tracks(\n",
    "        CLIENT_ID, \n",
    "        playlist_ID, \n",
    "        fields = 'items,uri,name,id,total', \n",
    "        limit  = _RESPONSE_LIMIT\n",
    "    )\n",
    "    Ntracks = response['total']\n",
    "    while 1:\n",
    "        trCount += len(response['items'])\n",
    "        plTracks.extend( response['items'] )\n",
    "        \n",
    "        if trCount >= Ntracks:\n",
    "            break\n",
    "    \n",
    "        response = spot.user_playlist_tracks(\n",
    "            CLIENT_ID, \n",
    "            playlist_ID, \n",
    "            fields = 'items,uri,name,id,total', \n",
    "            limit  = _RESPONSE_LIMIT,\n",
    "            offset = trCount\n",
    "        )\n",
    "    return plTracks\n",
    "\n",
    "\n",
    "def update_music_database( db, fDb ):\n",
    "    \"\"\" Update the database without overwriting important info \"\"\"\n",
    "    \n",
    "    db['playlists'].update( fDb['playlists'] )\n",
    "    \n",
    "    db['collectID'] = db['collectID'].union( fDb['collectID'] )\n",
    "    \n",
    "    db['review'].update( fDb['review'] )\n",
    "    \n",
    "    db['reviewID'] = db['reviewID'].union( fDb['reviewID'] )\n",
    "\n",
    "    for artID, artDct in fDb['artists'].items():\n",
    "        dct_i = dict()\n",
    "        dct_i.update( artDct )\n",
    "        if artID in db['artists']:\n",
    "            dct_i.update( db['artists'][ artID ] )\n",
    "            dct_i['releases'] = artDct['releases']\n",
    "            dct_i['releases'].extend( db['artists'][ artID ]['releases'] )\n",
    "        db['artists'][ artID ] = dct_i\n",
    "\n",
    "    for query in fDb['queries']:\n",
    "        db['queries'][ query ] = db['queries'].get( query, 0 ) + fDb['queries'][ query ]\n",
    "\n",
    "    db['genres'].update( fDb['genres'] )\n",
    "    \n",
    "\n",
    "def load_music_database( dataDir = _DATA_DIR, forceLoad = False ):\n",
    "    \"\"\" Find the latest music database, test for freshness, and set current db if fresh \"\"\"\n",
    "    global data\n",
    "    dbFiles = [os.path.join( dataDir, f ) for f in os.listdir( dataDir ) if (_DATA_PREFIX in str(f))]\n",
    "    if len( dbFiles ):\n",
    "        dbFiles.sort( reverse = True )\n",
    "        with open( dbFiles[0], 'rb' ) as f:\n",
    "            db = pickle.load( f )\n",
    "        if (((data['time'] - db['time']) <= _STALE_TIME_S) or forceLoad):\n",
    "            \n",
    "            # data.update( db )\n",
    "            update_music_database( data, db )\n",
    "            \n",
    "            print( f\"Loaded {dbFiles[0]}!\" )\n",
    "            return dbFiles[0]\n",
    "        else:\n",
    "            print( f\"File {dbFiles[0]} was STALE by {(data['time']-db['time']-_STALE_TIME_S)/_MOD_T_DAY_S} days!\" )\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_music_database( dataDct ):\n",
    "    \"\"\" Pickle `dataDct` to store current music collection data as well as search activity \"\"\"\n",
    "    print( f\"About to write {outPath} ...\" )\n",
    "    with open( outPath, 'wb' ) as f:\n",
    "        pickle.dump( dataDct, f )\n",
    "    print( \"COMPLETE!\" )\n",
    "\n",
    "\n",
    "def populate_playlist_data( dataDct, plDict, pause_s = 1.0 ):\n",
    "    \"\"\" Gather data across specified playlists \"\"\"\n",
    "    print( \"\\n### READ MUSIC COLLECTION ###\\n\" )\n",
    "    nuDB = load_music_database()\n",
    "    if nuDB is not None:\n",
    "        print( f\"Found current collection data at {nuDB}!\" )\n",
    "    else:\n",
    "        for plName_i, plID_i in plDict.items():\n",
    "            print( plName_i, '-', plID_i, '...' )\n",
    "            dataDct['playlists'][ plName_i ] = {\n",
    "                'ID'    : plID_i,\n",
    "                'tracks': fetch_entire_playlist( plID_i ),\n",
    "            }\n",
    "            \n",
    "            plSet_i = set([item['track']['id'] for item in dataDct['playlists'][ plName_i ]['tracks']])\n",
    "            dataDct['collectID'] = dataDct['collectID'].union( plSet_i )\n",
    "    \n",
    "            for track_j in dataDct['playlists'][ plName_i ]['tracks']:\n",
    "    \n",
    "                for artist_k in track_j['track']['artists']:\n",
    "                    artistID_j = artist_k['id']\n",
    "                    if artistID_j not in dataDct['artists']:\n",
    "                        dataDct['artists'][ artistID_j ] = { \n",
    "                            'name'    : track_j['track']['artists'][0]['name'], \n",
    "                            'count'   : 1, \n",
    "                            'releases': [track_j['track']['album']['release_date'],], \n",
    "                        }\n",
    "                    else:\n",
    "                        dataDct['artists'][ artistID_j ]['count'   ] += 1\n",
    "                        dataDct['artists'][ artistID_j ]['releases'].append( track_j['track']['album']['release_date'] )\n",
    "    \n",
    "            sleep( pause_s )\n",
    "    \n",
    "    print( \"\\n### COMPLETE ###\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f26f5-5906-409a-9093-eb48d1c17156",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab8a170-ba6c-41a4-a851-7bdb13d07bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########## CONTAINER FUNCTIONS #####################################################################\n",
    "\n",
    "def sort_keys_by_value( dct, reverse = True ):\n",
    "    \"\"\" Return a list of keys sorted by their (numeric) values \"\"\"\n",
    "    srtLst = list()\n",
    "    for k, v in dct.items():\n",
    "        srtLst.append( [v,k,] )\n",
    "    srtLst.sort( key = lambda x: x[0], reverse = reverse )\n",
    "    return [pair[1] for pair in srtLst] \n",
    "\n",
    "\n",
    "\n",
    "########## STRING ANALYSIS #########################################################################\n",
    "\n",
    "def levenshtein_dist( s1, s2 ):\n",
    "    \"\"\" Get the edit distance between two strings \"\"\"\n",
    "    # Author: Salvador Dali, https://stackoverflow.com/a/32558749\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]\n",
    "\n",
    "\n",
    "\n",
    "########## STATS & SAMPLING ########################################################################\n",
    "\n",
    "\n",
    "def total_pop( odds ):\n",
    "    \"\"\" Sum over all categories in the prior odds \"\"\"\n",
    "    total = 0\n",
    "    for k in odds:\n",
    "        total += odds[k]\n",
    "    return total\n",
    "\n",
    "\n",
    "def normalize_dist( odds_ ):\n",
    "    \"\"\" Normalize the distribution so that the sum equals 1.0 \"\"\"\n",
    "    total  = total_pop( odds_ )\n",
    "    rtnDst = dict()\n",
    "    for k in odds_:\n",
    "        rtnDst[k] = odds_[k] / total\n",
    "    return rtnDst\n",
    "\n",
    "\n",
    "def roll_outcome( odds ):\n",
    "    \"\"\" Get a random outcome from the distribution \"\"\"\n",
    "    oddsNorm = normalize_dist( odds )\n",
    "    distrib  = []\n",
    "    outcome  = []\n",
    "    total    = 0.0\n",
    "    for o, p in oddsNorm.items():\n",
    "        total += p\n",
    "        distrib.append( total )\n",
    "        outcome.append( o )\n",
    "    roll = random()\n",
    "    for i, p in enumerate( distrib ):\n",
    "        if roll <= p:\n",
    "            return outcome[i]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c7cc5-3ed3-4d66-892a-5e7199864955",
   "metadata": {},
   "source": [
    "# Mini-Genre Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee84d7bf-784a-4e06-a2b8-a5ee7ca2b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fetch_entire_playlist_with_audio_features( playlist_ID, pause_s = 1.00 ):\n",
    "    \"\"\" Get maximum infodump on all playlist tracks \"\"\"\n",
    "\n",
    "    plTracks = []\n",
    "    Ntracks  = get_playlist_length( playlist_ID )\n",
    "    trCount  = 0\n",
    "    trOffst  = 0\n",
    "\n",
    "    while trCount < Ntracks:\n",
    "\n",
    "        lim = min( _RESPONSE_LIMIT, Ntracks-trCount )\n",
    "\n",
    "        response = spot.user_playlist_tracks(\n",
    "            CLIENT_ID, \n",
    "            playlist_ID, \n",
    "            fields = 'items,uri,name,id,total', \n",
    "            limit  = lim,\n",
    "            offset = trCount\n",
    "        )\n",
    "        sleep( pause_s )\n",
    "\n",
    "        trCount  += len( response['items'] )\n",
    "        resTracks = response['items']\n",
    "        resIDs    = list()\n",
    "        \n",
    "        for item in resTracks:\n",
    "            resIDs.append( item['track']['id'] )\n",
    "\n",
    "        resFeatrs = spot.audio_features( resIDs )\n",
    "        # pprint( resFeatrs[0] )\n",
    "        sleep( pause_s )\n",
    "\n",
    "        for i, track_i in enumerate( resTracks ):\n",
    "            track_i.update( resFeatrs[i] )\n",
    "\n",
    "        plTracks.extend( resTracks )\n",
    "\n",
    "    return plTracks\n",
    "\n",
    "\n",
    "def get_track_vector( track ):\n",
    "    \"\"\" Express the track characteristics as a vector \"\"\"\n",
    "    return np.array([\n",
    "        track['speechiness'] * _V_SPEECH_FACTOR,\n",
    "        track['instrumentalness'] * _V_INSTR_FACTOR,\n",
    "        track['acousticness'] * _V_ACOUST_FACTOR,\n",
    "        track['danceability'] * _V_DANCE_FACTOR,\n",
    "        track['duration_ms'] * _V_DURATN_FACTOR,\n",
    "        track['energy'] * _V_ENERGY_FACTOR,\n",
    "        track['liveness'] * _V_LIVENS_FACTOR,\n",
    "        track['loudness'] * _V_LOUDNS_FACTOR,\n",
    "        (track['tempo']-45.7) * _V_TEMPO_FACTOR,\n",
    "        track['valence'] * _V_VALENC_FACTOR,\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_tracks_as_vectors( tracks ):\n",
    "    \"\"\" Convert all tracks to vectors \"\"\"\n",
    "    Mrows  = len( tracks )\n",
    "    if Mrows > 0:\n",
    "        Ncols  = len( get_track_vector( tracks[0] ) )\n",
    "        rtnMtx = np.zeros( (Mrows, Ncols,) ) \n",
    "        for i, trk in enumerate( tracks ):\n",
    "            rtnMtx[i,:] = get_track_vector( trk )\n",
    "        return rtnMtx\n",
    "    else:\n",
    "        return list()\n",
    "\n",
    "\n",
    "def vector_distance_to_genre( qVec, genreDct ):\n",
    "    \"\"\" Get Euclidean distance between `qVec` and the nearest track vector of `genreDct` \"\"\"\n",
    "    return genreDct['kdTree'].query( qVec )[0]\n",
    "    \n",
    "\n",
    "def track_distance_to_genre( qTrack, genreDct ):\n",
    "    \"\"\" Get Euclidean distance between `qTrack` and the nearest track vector of `genreDct` \"\"\"\n",
    "    return vector_distance_to_genre( get_track_vector( qTrack ), genreDct )\n",
    "\n",
    "\n",
    "def assign_vectors_to_tracks( tracks ):\n",
    "    \"\"\" Store vector info in each track dictionary \"\"\"\n",
    "    matxTrks = get_tracks_as_vectors( tracks )\n",
    "    for i, vec_i in enumerate( matxTrks ):\n",
    "        trk_i = tracks[i]\n",
    "        trk_i['vector'] = vec_i\n",
    "    print( f\"Stored vectors for {len(tracks)} tracks!\" )\n",
    "\n",
    "\n",
    "def fetch_collection_with_audio_features( dataDct, plDct, rvDct = None, pause_s = 3.0, renewSets = True ):\n",
    "    \"\"\" Get maximum infodump on all playlists \"\"\"\n",
    "\n",
    "    if renewSets:\n",
    "        dataDct['collectID'] = set([])\n",
    "    \n",
    "    print( \"##### Get Collection Data #####\" )\n",
    "    for plName_i, plID_i in plDct.items():\n",
    "        print( plName_i, '-', plID_i, '...' )\n",
    "        tracks_i = fetch_entire_playlist_with_audio_features( plID_i )\n",
    "        assign_vectors_to_tracks( tracks_i )\n",
    "        dataDct['playlists'][ plName_i ] = {\n",
    "            'ID'    : plID_i,\n",
    "            'tracks': tracks_i,\n",
    "            'len'   : len( tracks_i ),\n",
    "        }\n",
    "        dataDct['collectID'] = dataDct['collectID'].union( set([trk['track']['id'] for trk in tracks_i]) )\n",
    "\n",
    "        # Catalog artists from collection tracks (Req'd for (Sub-)Search 01)\n",
    "        for track_j in tracks_i:\n",
    "            for artist_k in track_j['track']['artists']:\n",
    "                artistID_j = artist_k['id']\n",
    "                if artistID_j not in dataDct['artists']:\n",
    "                    dataDct['artists'][ artistID_j ] = { \n",
    "                        'name'    : track_j['track']['artists'][0]['name'], \n",
    "                        'count'   : 1, \n",
    "                        'releases': [track_j['track']['album']['release_date'],], \n",
    "                    }\n",
    "                else:\n",
    "                    dataDct['artists'][ artistID_j ]['count'   ] += 1\n",
    "                    dataDct['artists'][ artistID_j ]['releases'].append( track_j['track']['album']['release_date'] )\n",
    "        \n",
    "        sleep( pause_s )\n",
    "\n",
    "    if rvDct is not None:\n",
    "        print( \"\\n##### Get Review Data #####\" )\n",
    "        for plName_i, plID_i in rvDct.items():\n",
    "            print( plName_i, '-', plID_i, '...' )\n",
    "            tracks_i = fetch_entire_playlist_with_audio_features( plID_i )\n",
    "            assign_vectors_to_tracks( tracks_i )\n",
    "            dataDct['review'][ plName_i ] = {\n",
    "                'ID'    : plID_i,\n",
    "                'tracks': tracks_i,\n",
    "                'len'   : len( tracks_i ),\n",
    "            }\n",
    "            dataDct['reviewID'] = dataDct['reviewID'].union( set([trk['track']['id'] for trk in tracks_i]) )\n",
    "            sleep( pause_s )\n",
    "\n",
    "    print( \"\\n##### Complete #####\" )\n",
    "\n",
    "\n",
    "def analyze_db_vector_spread( db ):\n",
    "    \"\"\" Gather info for feature scaling and print it for manual scaling update \"\"\"\n",
    "    rtnMatx = np.ones( (2, _V_NUM_FEATURES,) )\n",
    "    rtnMatx[0,:] *=  1e6\n",
    "    rtnMatx[1,:] *= -1e6\n",
    "    totlDct = dict()\n",
    "    totlDct.update( db['playlists'] )\n",
    "    totlDct.update( db['review'   ] )\n",
    "    for plName_i, playls_i in totlDct.items():\n",
    "        if len( playls_i['tracks'] ):\n",
    "            matx_i = get_tracks_as_vectors( playls_i['tracks'] )\n",
    "            mMin_i = np.min( matx_i, axis = 0 )\n",
    "            mMax_i = np.max( matx_i, axis = 0 )\n",
    "            for j in range( _V_NUM_FEATURES ):\n",
    "                if mMin_i[j] < rtnMatx[0,j]:\n",
    "                    rtnMatx[0,j] = mMin_i[j]\n",
    "                if mMax_i[j] > rtnMatx[1,j]:\n",
    "                    rtnMatx[1,j] = mMax_i[j]\n",
    "    for j in range( _V_NUM_FEATURES ):\n",
    "        print( f\"Feature {j+1}, Span: {rtnMatx[1,j] - rtnMatx[0,j]}, Min: {rtnMatx[0,j]}\" )\n",
    "    return rtnMatx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9afb47f-9873-4f92-8c53-ab2438096405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/Study-Music-Data_2024-09-01T20:53:35.pkl!\n"
     ]
    }
   ],
   "source": [
    "load_music_database( forceLoad = 1 );\n",
    "# fetch_collection_with_audio_features( data, playlist, review, pause_s = 3.0 )\n",
    "# analyze_db_vector_spread( data );\n",
    "# save_music_database( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f427aff-a309-4d40-b0ab-57530178cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_vector_ops( gnre ):\n",
    "    \"\"\" Calculate track vectors and properties derived from them \"\"\"\n",
    "    gnre['vectors'] = get_tracks_as_vectors( gnre['tracks'] )\n",
    "    gnre['len']     = len( gnre['tracks'] )\n",
    "    if gnre['len'] > 1:\n",
    "        cntr = np.mean( gnre['vectors'], axis = 0 )\n",
    "        dim  = len( cntr )\n",
    "        for i in range( gnre['len'] ):\n",
    "            pnt_i   = gnre['vectors'][i,:]\n",
    "            dist_i  = np.linalg.norm( np.subtract( cntr, pnt_i ) )\n",
    "            alpha_i = np.exp( -dist_i )\n",
    "            cntr    = cntr * (1.0 - alpha_i) + pnt_i * alpha_i\n",
    "        gnre['center'] = cntr # 2024-08-16: This is probably guaranteed to be inside the convex hull\n",
    "        gnre['kdTree'] = cKDTree( gnre['vectors'], balanced_tree = False, compact_nodes = False )\n",
    "    elif gnre['len'] > 0:\n",
    "        gnre['center'] = gnre['vectors'][0]\n",
    "        gnre['kdTree'] = cKDTree( gnre['vectors'], balanced_tree = False, compact_nodes = False )\n",
    "    else:\n",
    "        gnre['center'] = None\n",
    "        gnre['kdTree'] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787390e9-e2f2-4009-9b6d-86f64bb025ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "def set_genre_membership( db ):\n",
    "    \"\"\" Make sure all genres have a membership ID hash \"\"\"\n",
    "    for gnreID_k, genre_k in db['genres'].items():\n",
    "        if ('trackIDs' not in genre_k):\n",
    "            genre_k['trackIDs'] = set([])\n",
    "        for l, track_l in enumerate( genre_k['tracks'] ):\n",
    "            genre_k['trackIDs'].add( track_l['id'] )\n",
    "    \n",
    "\n",
    "def get_homeless_tracks( db ):\n",
    "    \"\"\" Return a list of tracks not assicated with a current mini-genre \"\"\"\n",
    "    set_genre_membership( db )\n",
    "    rtnLst = list()\n",
    "    for plName_i, playls_i in db['playlists'].items():\n",
    "        for j, track_j in enumerate( playls_i['tracks'] ):\n",
    "            found   = False\n",
    "            trkID_j = track_j['id']\n",
    "            for gnreID_k, genre_k in db['genres'].items():\n",
    "                if trkID_j in genre_k['trackIDs']:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                rtnLst.append( track_j )\n",
    "    shuffle( rtnLst )\n",
    "    print( f\"Found {len(rtnLst)} unaffiliated tracks!\" )\n",
    "    return rtnLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80c597-869d-46c7-9590-96884f000584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
