{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2879baf-23df-4b08-9987-3fd4c94a0ae0",
   "metadata": {},
   "source": [
    "# Init & Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab3425f-fee1-4fe5-89ae-aa74e181cb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN OBTAINED\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from random import randrange\n",
    "from time import sleep\n",
    "from pprint import pprint\n",
    "\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## Client Info ##\n",
    "CLIENT_ID     = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "CLIENT_SCOPE  = \"user-follow-modify playlist-modify-private playlist-modify-public\"\n",
    "USER_NAME     = \"31ytgsr7wdmiaroy77msqpiupdsi\"\n",
    "REDIR_URI     = \"https://github.com/jwatson-CO-edu/yt_shuffle_so_good\"\n",
    "AUTH_URL      = 'https://accounts.spotify.com/api/token'\n",
    "BASE_URL      = 'https://api.spotify.com/v1/'\n",
    "## API Info ##\n",
    "_RESPONSE_LIMIT = 100\n",
    "\n",
    "with open( \"../keys/spot_ID.txt\" , 'r' ) as f:\n",
    "    CLIENT_ID = f.readlines()[0].strip()\n",
    "\n",
    "with open( \"../keys/spot_SECRET.txt\" , 'r' ) as f:\n",
    "    CLIENT_SECRET = f.readlines()[0].strip()\n",
    "\n",
    "token = None\n",
    "token = util.prompt_for_user_token(\n",
    "    username      = USER_NAME,\n",
    "    scope         = CLIENT_SCOPE,\n",
    "    client_id     = CLIENT_ID,\n",
    "    client_secret = CLIENT_SECRET,\n",
    "    redirect_uri  = REDIR_URI\n",
    ")\n",
    "\n",
    "print( token )\n",
    "\n",
    "spot = spotipy.Spotify( auth = token )\n",
    "clear_output( wait = True )\n",
    "sleep( 5 )\n",
    "print( \"TOKEN OBTAINED\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbe707-21d9-44f7-91f8-752912b73ea5",
   "metadata": {},
   "source": [
    "# Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89ca361-cea4-41e0-b50e-86e0c57b0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "playlist = {\n",
    "    'study01' : \"0a2qoe6S7lYeZ6nlhZdA0v\",\n",
    "    'study02' : \"6gbtR2cBq5PvkghidCvvGk\",\n",
    "    'study03' : \"3o3lN2qntdEV7UKTuuC77K\",\n",
    "    'study04' : \"41sFSisljvBDMBXtpp5NIw\",\n",
    "    'study05' : \"02iS5AFGp8YVuUUqcQf8ys\",\n",
    "    'study06' : \"6KI7A4MWrSM7EyKRUjxIi1\",\n",
    "    'study07' : \"3V055Md2JdrUT8tX0af7di\",\n",
    "    'study08' : \"0tspdJlwSgiyf2O9PO6QaP\",\n",
    "    'study09' : \"5mHRBFoQtYy2izeZ66pG95\",\n",
    "    'study10' : \"3832xeKGEOAXFJqE4K8kIq\",\n",
    "    'study11' : \"65MXR4dubPL9t0P4dgTWvn\",\n",
    "    'study12' : \"0ecSAfnD4CulIVnLt26ukI\",\n",
    "    'study13' : \"7K9ucByFRgDuZk8KMHeJkL\",\n",
    "    'zd_Over' : \"0v26bHydUxcGC5EbMlkjzG\",\n",
    "}\n",
    "\n",
    "dupeDump = \"1VPXM7m1by79EdEzDqGsHy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee7de4-d80c-49e6-801d-0ee48476feaf",
   "metadata": {},
   "source": [
    "# Playlist Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3589f653-54a5-4db6-885b-ec0556fd6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_entire_playlist( playlist_ID ):\n",
    "    \"\"\" Get infodump on all plalist tracks \"\"\"\n",
    "    plTracks = []\n",
    "    trCount  = 0\n",
    "    response = spot.user_playlist_tracks(\n",
    "        CLIENT_ID, \n",
    "        playlist_ID, \n",
    "        fields = 'items,uri,name,id,total', \n",
    "        limit  = _RESPONSE_LIMIT\n",
    "    )\n",
    "    Ntracks = response['total']\n",
    "    while 1:\n",
    "        trCount += len(response['items'])\n",
    "        plTracks.extend( response['items'] )\n",
    "        \n",
    "        if trCount >= Ntracks:\n",
    "            break\n",
    "    \n",
    "        response = spot.user_playlist_tracks(\n",
    "            CLIENT_ID, \n",
    "            playlist_ID, \n",
    "            fields = 'items,uri,name,id,total', \n",
    "            limit  = _RESPONSE_LIMIT,\n",
    "            offset = trCount\n",
    "        )\n",
    "    return plTracks\n",
    "\n",
    "\n",
    "def get_playlist_unique_ID_set( plItems ):\n",
    "    \"\"\" Get all IDs from the playlist without repeats \"\"\"\n",
    "    uniqID = set([])\n",
    "    for item in plItems:\n",
    "        uniqID.add( item['track']['id'] )\n",
    "    print( f\"Playlist of {len(plItems)} has {len(uniqID)} unique tracks!\" )\n",
    "    return uniqID \n",
    "\n",
    "def get_playlist_series_unique_ID_set( plDict ):\n",
    "    \"\"\" Get all IDs from each playlist without repeats \"\"\"\n",
    "    \n",
    "    print( f\"##### First Pass #####\\n\" )\n",
    "    bgnSets = []\n",
    "    nameLst = []\n",
    "    idList  = []\n",
    "    for plName, plID in plDict.items():\n",
    "        print( f\"### {plName} ###\" )\n",
    "        nameLst.append( plName )\n",
    "        idList.append( plID )\n",
    "        bgnSets.append( get_playlist_unique_ID_set( fetch_entire_playlist( plID ) ) )\n",
    "        print()\n",
    "\n",
    "    print( f\"##### Second Pass #####\\n\" )\n",
    "    endSets = [ bgnSets[0], ]\n",
    "    print( len( endSets[0] ), end = \", \", flush = True )\n",
    "    for trackSet in bgnSets[1:]:\n",
    "        nuSet = set([])\n",
    "        for elem in trackSet:\n",
    "            found = False\n",
    "            for compSet in endSets:\n",
    "                if elem in compSet:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                nuSet.add( elem )\n",
    "        print( len( nuSet ), end = \", \", flush = True )\n",
    "        if len( nuSet ):\n",
    "            endSets.append( nuSet )\n",
    "    print( '\\n' )\n",
    "    return zip( nameLst, idList, endSets )\n",
    "\n",
    "\n",
    "def create_dupe_removal_jobs( plDict, pause_s = 0.5 ):\n",
    "    \"\"\" Remove all duplicates from each playlist while attempting to preserve them in case of a massive fuckup \"\"\"    \n",
    "    uniqList = list()\n",
    "    srtdKeys = sorted( list( plDict.keys() ) )\n",
    "    dumpList = list()\n",
    "    plIDlist = list()\n",
    "\n",
    "    def p_exists_in_prev( itemID, currDex ):\n",
    "        \"\"\" Return True if `itemID` exists in a playlist before `currDex`, Otherwise return False \"\"\"\n",
    "        for plSet in uniqList[ :currDex ]:\n",
    "            if itemID in plSet:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # 1. For every playlist in the dict, do\n",
    "    for i, plName in enumerate( srtdKeys ):\n",
    "\n",
    "        print( f\"##### Playlist {i+1}: {plName} #####\" )\n",
    "        \n",
    "        # 2. Fetch playlist and establish a running set\n",
    "        plID      = plDict[ plName ]\n",
    "        trkList_i = fetch_entire_playlist( plID )\n",
    "        trkSet_i  = set([])\n",
    "        dumpLst_i = list()\n",
    "        plIDlist.append( plID )\n",
    "        print( f\"Fetched {len(trkList_i)} tracks!\" )\n",
    "        \n",
    "        # 3. For every track j in playlist i, do\n",
    "        for j, track_j in enumerate( trkList_i ):\n",
    "\n",
    "            p_dump_j = False\n",
    "            \n",
    "            # 4. Test 1: Did we find this song earlier in the playlist?\n",
    "            trackID_j = track_j['track']['id']\n",
    "            if trackID_j in trkSet_i:\n",
    "                dumpLst_i.append( trackID_j )\n",
    "                p_dump_j = True\n",
    "\n",
    "            # 5. Test 2: Did we find this song in and earlier playlist?\n",
    "            if (not p_dump_j) and p_exists_in_prev( trackID_j, i ):\n",
    "                dumpLst_i.append( trackID_j )\n",
    "                p_dump_j = True\n",
    "            \n",
    "            # 6. Uniqify\n",
    "            if not p_dump_j:\n",
    "                trkSet_i.add( trackID_j )\n",
    "            \n",
    "        # 7. Store track set i and dump list\n",
    "        uniqList.append( trkSet_i )\n",
    "        dumpList.append( dumpLst_i )\n",
    "        print( f\"In {plName}/{plID}: Retain {len(trkSet_i)}, Dump {len(dumpLst_i)}, Valid? {(len(trkSet_i)+len(dumpLst_i))==len(trkList_i)}\\n\" )\n",
    "        sleep( pause_s )\n",
    "\n",
    "    # N. Return removal job list\n",
    "    return list( zip( plIDlist, dumpList ) )\n",
    "            \n",
    "\n",
    "def run_dupe_removal_jobs( jobList, plTarget, pause_s = 0.5 ):\n",
    "    \"\"\" Run jobs created in `create_dupe_removal_jobs` and store them in `plTarget` in the event of a massive fuckup \"\"\"\n",
    "    print( f\"########## About to run {len(jobList)} jobs ... ##########\\n\" )\n",
    "    for i, (plID_i, remLst_i) in enumerate( jobList ):\n",
    "        \n",
    "        print( f\"##### Job {i+1}: {plID_i}, {len(remLst_i)} to remove ... #####\" )\n",
    "        \n",
    "        print( f\"Venting dupes to {plTarget} ...\" )\n",
    "        spot.user_playlist_add_tracks( CLIENT_ID, plTarget, remLst_i )\n",
    "        sleep( pause_s )\n",
    "        \n",
    "        print( f\"removing dupes from {plID_i} ...\" )\n",
    "        spot.playlist_remove_all_occurrences_of_items( plID_i, remLst_i )\n",
    "        sleep( pause_s )\n",
    "        \n",
    "        print()\n",
    "    print( f\"########## Completed {len(jobList)} jobs! ##########\\n\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfc43b-4abf-4ff5-bc71-5fa00a9acdd1",
   "metadata": {},
   "source": [
    "# Identify Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad088a6-c068-4631-964f-a3049e242887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Playlist 1: study01 #####\n",
      "Fetched 400 tracks!\n",
      "In study01/0a2qoe6S7lYeZ6nlhZdA0v: Retain 397, Dump 3, Valid? True\n",
      "\n",
      "##### Playlist 2: study02 #####\n",
      "Fetched 400 tracks!\n",
      "In study02/6gbtR2cBq5PvkghidCvvGk: Retain 392, Dump 8, Valid? True\n",
      "\n",
      "##### Playlist 3: study03 #####\n",
      "Fetched 400 tracks!\n",
      "In study03/3o3lN2qntdEV7UKTuuC77K: Retain 359, Dump 41, Valid? True\n",
      "\n",
      "##### Playlist 4: study04 #####\n",
      "Fetched 400 tracks!\n",
      "In study04/41sFSisljvBDMBXtpp5NIw: Retain 374, Dump 26, Valid? True\n",
      "\n",
      "##### Playlist 5: study05 #####\n",
      "Fetched 400 tracks!\n",
      "In study05/02iS5AFGp8YVuUUqcQf8ys: Retain 373, Dump 27, Valid? True\n",
      "\n",
      "##### Playlist 6: study06 #####\n",
      "Fetched 400 tracks!\n",
      "In study06/6KI7A4MWrSM7EyKRUjxIi1: Retain 375, Dump 25, Valid? True\n",
      "\n",
      "##### Playlist 7: study07 #####\n",
      "Fetched 400 tracks!\n",
      "In study07/3V055Md2JdrUT8tX0af7di: Retain 366, Dump 34, Valid? True\n",
      "\n",
      "##### Playlist 8: study08 #####\n",
      "Fetched 464 tracks!\n",
      "In study08/0tspdJlwSgiyf2O9PO6QaP: Retain 436, Dump 28, Valid? True\n",
      "\n",
      "##### Playlist 9: study09 #####\n",
      "Fetched 400 tracks!\n",
      "In study09/5mHRBFoQtYy2izeZ66pG95: Retain 350, Dump 50, Valid? True\n",
      "\n",
      "##### Playlist 10: study10 #####\n",
      "Fetched 401 tracks!\n",
      "In study10/3832xeKGEOAXFJqE4K8kIq: Retain 372, Dump 29, Valid? True\n",
      "\n",
      "##### Playlist 11: study11 #####\n",
      "Fetched 400 tracks!\n",
      "In study11/65MXR4dubPL9t0P4dgTWvn: Retain 353, Dump 47, Valid? True\n",
      "\n",
      "##### Playlist 12: study12 #####\n",
      "Fetched 400 tracks!\n",
      "In study12/0ecSAfnD4CulIVnLt26ukI: Retain 339, Dump 61, Valid? True\n",
      "\n",
      "##### Playlist 13: study13 #####\n",
      "Fetched 400 tracks!\n",
      "In study13/7K9ucByFRgDuZk8KMHeJkL: Retain 350, Dump 50, Valid? True\n",
      "\n",
      "##### Playlist 14: zc_Over #####\n",
      "Fetched 465 tracks!\n",
      "In zc_Over/5HmNkICbTDCEwEXUJPdTss: Retain 415, Dump 50, Valid? True\n",
      "\n",
      "##### Playlist 15: zd_Over #####\n",
      "Fetched 241 tracks!\n",
      "In zd_Over/0v26bHydUxcGC5EbMlkjzG: Retain 225, Dump 16, Valid? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobList = create_dupe_removal_jobs( playlist )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d02ed-a301-47d7-80a0-5368994087ba",
   "metadata": {},
   "source": [
    "# Move Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac26265-6dde-4628-98d5-303561121d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## About to run 15 jobs ... ##########\n",
      "\n",
      "##### Job 1: 0a2qoe6S7lYeZ6nlhZdA0v, 3 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 0a2qoe6S7lYeZ6nlhZdA0v ...\n",
      "\n",
      "##### Job 2: 6gbtR2cBq5PvkghidCvvGk, 8 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 6gbtR2cBq5PvkghidCvvGk ...\n",
      "\n",
      "##### Job 3: 3o3lN2qntdEV7UKTuuC77K, 41 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 3o3lN2qntdEV7UKTuuC77K ...\n",
      "\n",
      "##### Job 4: 41sFSisljvBDMBXtpp5NIw, 26 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 41sFSisljvBDMBXtpp5NIw ...\n",
      "\n",
      "##### Job 5: 02iS5AFGp8YVuUUqcQf8ys, 27 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 02iS5AFGp8YVuUUqcQf8ys ...\n",
      "\n",
      "##### Job 6: 6KI7A4MWrSM7EyKRUjxIi1, 25 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 6KI7A4MWrSM7EyKRUjxIi1 ...\n",
      "\n",
      "##### Job 7: 3V055Md2JdrUT8tX0af7di, 34 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 3V055Md2JdrUT8tX0af7di ...\n",
      "\n",
      "##### Job 8: 0tspdJlwSgiyf2O9PO6QaP, 28 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 0tspdJlwSgiyf2O9PO6QaP ...\n",
      "\n",
      "##### Job 9: 5mHRBFoQtYy2izeZ66pG95, 50 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 5mHRBFoQtYy2izeZ66pG95 ...\n",
      "\n",
      "##### Job 10: 3832xeKGEOAXFJqE4K8kIq, 29 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 3832xeKGEOAXFJqE4K8kIq ...\n",
      "\n",
      "##### Job 11: 65MXR4dubPL9t0P4dgTWvn, 47 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 65MXR4dubPL9t0P4dgTWvn ...\n",
      "\n",
      "##### Job 12: 0ecSAfnD4CulIVnLt26ukI, 61 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 0ecSAfnD4CulIVnLt26ukI ...\n",
      "\n",
      "##### Job 13: 7K9ucByFRgDuZk8KMHeJkL, 50 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 7K9ucByFRgDuZk8KMHeJkL ...\n",
      "\n",
      "##### Job 14: 5HmNkICbTDCEwEXUJPdTss, 50 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 5HmNkICbTDCEwEXUJPdTss ...\n",
      "\n",
      "##### Job 15: 0v26bHydUxcGC5EbMlkjzG, 16 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 0v26bHydUxcGC5EbMlkjzG ...\n",
      "\n",
      "########## Completed 15 jobs! ##########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_dupe_removal_jobs( jobList, dupeDump, pause_s = 0.5 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
