{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2879baf-23df-4b08-9987-3fd4c94a0ae0",
   "metadata": {},
   "source": [
    "# Init & Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab3425f-fee1-4fe5-89ae-aa74e181cb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN OBTAINED\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from random import randrange\n",
    "from time import sleep\n",
    "from pprint import pprint\n",
    "\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## Client Info ##\n",
    "CLIENT_ID     = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "CLIENT_SCOPE  = \"user-follow-modify playlist-modify-private playlist-modify-public\"\n",
    "USER_NAME     = \"31ytgsr7wdmiaroy77msqpiupdsi\"\n",
    "REDIR_URI     = \"https://github.com/jwatson-CO-edu/yt_shuffle_so_good\"\n",
    "AUTH_URL      = 'https://accounts.spotify.com/api/token'\n",
    "BASE_URL      = 'https://api.spotify.com/v1/'\n",
    "## API Info ##\n",
    "_RESPONSE_LIMIT = 100\n",
    "\n",
    "with open( \"../keys/spot_ID.txt\" , 'r' ) as f:\n",
    "    CLIENT_ID = f.readlines()[0].strip()\n",
    "\n",
    "with open( \"../keys/spot_SECRET.txt\" , 'r' ) as f:\n",
    "    CLIENT_SECRET = f.readlines()[0].strip()\n",
    "\n",
    "token = None\n",
    "token = util.prompt_for_user_token(\n",
    "    username      = USER_NAME,\n",
    "    scope         = CLIENT_SCOPE,\n",
    "    client_id     = CLIENT_ID,\n",
    "    client_secret = CLIENT_SECRET,\n",
    "    redirect_uri  = REDIR_URI\n",
    ")\n",
    "\n",
    "print( token )\n",
    "\n",
    "spot = spotipy.Spotify( auth = token )\n",
    "clear_output( wait = True )\n",
    "sleep( 2 )\n",
    "print( \"TOKEN OBTAINED\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbe707-21d9-44f7-91f8-752912b73ea5",
   "metadata": {},
   "source": [
    "# Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89ca361-cea4-41e0-b50e-86e0c57b0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "playlist = {\n",
    "    'study01' : \"0a2qoe6S7lYeZ6nlhZdA0v\",\n",
    "    'study02' : \"6gbtR2cBq5PvkghidCvvGk\",\n",
    "    'study03' : \"3o3lN2qntdEV7UKTuuC77K\",\n",
    "    'study04' : \"41sFSisljvBDMBXtpp5NIw\",\n",
    "    'study05' : \"02iS5AFGp8YVuUUqcQf8ys\",\n",
    "    'study06' : \"6KI7A4MWrSM7EyKRUjxIi1\",\n",
    "    'study07' : \"3V055Md2JdrUT8tX0af7di\",\n",
    "    'study08' : \"0tspdJlwSgiyf2O9PO6QaP\",\n",
    "    'study09' : \"5mHRBFoQtYy2izeZ66pG95\",\n",
    "    'study10' : \"3832xeKGEOAXFJqE4K8kIq\",\n",
    "    'study11' : \"65MXR4dubPL9t0P4dgTWvn\",\n",
    "    'study12' : \"0ecSAfnD4CulIVnLt26ukI\",\n",
    "    'study13' : \"7K9ucByFRgDuZk8KMHeJkL\",\n",
    "    'zd_Over' : \"0v26bHydUxcGC5EbMlkjzG\",\n",
    "}\n",
    "\n",
    "dupeDump = \"1VPXM7m1by79EdEzDqGsHy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee7de4-d80c-49e6-801d-0ee48476feaf",
   "metadata": {},
   "source": [
    "# Playlist Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3589f653-54a5-4db6-885b-ec0556fd6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_entire_playlist( playlist_ID ):\n",
    "    \"\"\" Get infodump on all plalist tracks \"\"\"\n",
    "    plTracks = []\n",
    "    trCount  = 0\n",
    "    response = spot.user_playlist_tracks(\n",
    "        CLIENT_ID, \n",
    "        playlist_ID, \n",
    "        fields = 'items,uri,name,id,total', \n",
    "        limit  = _RESPONSE_LIMIT\n",
    "    )\n",
    "    Ntracks = response['total']\n",
    "    while 1:\n",
    "        trCount += len(response['items'])\n",
    "        plTracks.extend( response['items'] )\n",
    "        \n",
    "        if trCount >= Ntracks:\n",
    "            break\n",
    "    \n",
    "        response = spot.user_playlist_tracks(\n",
    "            CLIENT_ID, \n",
    "            playlist_ID, \n",
    "            fields = 'items,uri,name,id,total', \n",
    "            limit  = _RESPONSE_LIMIT,\n",
    "            offset = trCount\n",
    "        )\n",
    "    return plTracks\n",
    "\n",
    "\n",
    "def get_playlist_unique_ID_set( plItems ):\n",
    "    \"\"\" Get all IDs from the playlist without repeats \"\"\"\n",
    "    uniqID = set([])\n",
    "    for item in plItems:\n",
    "        uniqID.add( item['track']['id'] )\n",
    "    print( f\"Playlist of {len(plItems)} has {len(uniqID)} unique tracks!\" )\n",
    "    return uniqID \n",
    "    \n",
    "\n",
    "def get_playlist_series_unique_ID_set( plDict ):\n",
    "    \"\"\" Get all IDs from each playlist without repeats \"\"\"\n",
    "    \n",
    "    print( f\"##### First Pass #####\\n\" )\n",
    "    bgnSets = []\n",
    "    nameLst = []\n",
    "    idList  = []\n",
    "    for plName, plID in plDict.items():\n",
    "        print( f\"### {plName} ###\" )\n",
    "        nameLst.append( plName )\n",
    "        idList.append( plID )\n",
    "        bgnSets.append( get_playlist_unique_ID_set( fetch_entire_playlist( plID ) ) )\n",
    "        print()\n",
    "\n",
    "    print( f\"##### Second Pass #####\\n\" )\n",
    "    endSets = [ bgnSets[0], ]\n",
    "    print( len( endSets[0] ), end = \", \", flush = True )\n",
    "    for trackSet in bgnSets[1:]:\n",
    "        nuSet = set([])\n",
    "        for elem in trackSet:\n",
    "            found = False\n",
    "            for compSet in endSets:\n",
    "                if elem in compSet:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                nuSet.add( elem )\n",
    "        print( len( nuSet ), end = \", \", flush = True )\n",
    "        if len( nuSet ):\n",
    "            endSets.append( nuSet )\n",
    "    print( '\\n' )\n",
    "    return zip( nameLst, idList, endSets )\n",
    "\n",
    "\n",
    "def create_dupe_removal_jobs( plDict, pause_s = 0.5 ):\n",
    "    \"\"\" Remove all duplicates from each playlist while attempting to preserve them in case of a massive fuckup \"\"\"    \n",
    "    uniqList = list()\n",
    "    srtdKeys = sorted( list( plDict.keys() ) )\n",
    "    dumpList = list()\n",
    "    plIDlist = list()\n",
    "\n",
    "    def p_exists_in_prev( itemID, currDex ):\n",
    "        \"\"\" Return True if `itemID` exists in a playlist before `currDex`, Otherwise return False \"\"\"\n",
    "        for plSet in uniqList[ :currDex ]:\n",
    "            if itemID in plSet:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # 1. For every playlist in the dict, do\n",
    "    for i, plName in enumerate( srtdKeys ):\n",
    "\n",
    "        print( f\"##### Playlist {i+1}: {plName} #####\" )\n",
    "        \n",
    "        # 2. Fetch playlist and establish a running set\n",
    "        plID      = plDict[ plName ]\n",
    "        trkList_i = fetch_entire_playlist( plID )\n",
    "        trkSet_i  = set([])\n",
    "        dumpLst_i = list()\n",
    "        plIDlist.append( plID )\n",
    "        origLen_i = len(trkList_i)\n",
    "        print( f\"Fetched {origLen_i} tracks!\" )\n",
    "        \n",
    "        # 3. For every track j in playlist i, do\n",
    "        j = 0\n",
    "        while j < len( trkList_i ):\n",
    "\n",
    "            track_j  = trkList_i[j]\n",
    "            p_dump_j = False\n",
    "            \n",
    "            # 4. Test 1: Did we find this song earlier in the playlist?\n",
    "            trackID_j = track_j['track']['id']\n",
    "            if trackID_j in trkSet_i:\n",
    "                dumpLst_i.append( (trackID_j, j,) )\n",
    "                p_dump_j = True\n",
    "                trkList_i.pop(j)\n",
    "\n",
    "            # 5. Test 2: Did we find this song in and earlier playlist?\n",
    "            if (not p_dump_j) and p_exists_in_prev( trackID_j, i ):\n",
    "                dumpLst_i.append( (trackID_j, j,) )\n",
    "                p_dump_j = True\n",
    "                trkList_i.pop(j)\n",
    "            \n",
    "            # 6. Uniqify\n",
    "            if not p_dump_j:\n",
    "                trkSet_i.add( trackID_j )\n",
    "                j += 1\n",
    "            \n",
    "        # 7. Store track set i and dump list\n",
    "        uniqList.append( trkSet_i )\n",
    "        dumpList.append( dumpLst_i )\n",
    "        print( f\"In {plName}/{plID}: Retain {len(trkSet_i)}, Dump {len(dumpLst_i)}, Valid? {(len(trkSet_i)+len(dumpLst_i))==origLen_i}\\n\" )\n",
    "        sleep( pause_s )\n",
    "\n",
    "    # N. Return removal job list\n",
    "    return list( zip( plIDlist, dumpList ) )\n",
    "            \n",
    "\n",
    "def run_dupe_removal_jobs( jobList, plTarget, pause_s = 0.5 ):\n",
    "    \"\"\" Run jobs created in `create_dupe_removal_jobs` and store them in `plTarget` in the event of a massive fuckup \"\"\"\n",
    "    print( f\"########## About to run {len(jobList)} jobs ... ##########\\n\" )\n",
    "    for i, (plID_i, remLst_i) in enumerate( jobList ):\n",
    "        print( f\"##### Job {i+1}: {plID_i}, {len(remLst_i)} to remove ... #####\" )\n",
    "\n",
    "        if len( remLst_i ):\n",
    "            remvLs_i = [item[0] for item in remLst_i]\n",
    "            print( f\"Venting dupes to {plTarget} ...\" )\n",
    "            spot.user_playlist_add_tracks( CLIENT_ID, plTarget, remvLs_i )\n",
    "            sleep( pause_s )\n",
    "    \n",
    "            print( f\"removing dupes from {plID_i} ...\" )\n",
    "            for (trackID, j) in remLst_i:\n",
    "                \n",
    "                res = spot.playlist_remove_specific_occurrences_of_items( \n",
    "                    plID_i, \n",
    "                    [{'uri': trackID, 'positions':[j,]},]\n",
    "                )\n",
    "                print( \"\\tRemove:\", trackID, j, res )\n",
    "                sleep( pause_s )\n",
    "        print()\n",
    "    print( f\"########## Completed {len(jobList)} jobs! ##########\\n\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfc43b-4abf-4ff5-bc71-5fa00a9acdd1",
   "metadata": {},
   "source": [
    "# Identify Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad088a6-c068-4631-964f-a3049e242887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Playlist 1: study01 #####\n",
      "Fetched 400 tracks!\n",
      "In study01/0a2qoe6S7lYeZ6nlhZdA0v: Retain 400, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 2: study02 #####\n",
      "Fetched 400 tracks!\n",
      "In study02/6gbtR2cBq5PvkghidCvvGk: Retain 400, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 3: study03 #####\n",
      "Fetched 400 tracks!\n",
      "In study03/3o3lN2qntdEV7UKTuuC77K: Retain 400, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 4: study04 #####\n",
      "Fetched 400 tracks!\n",
      "In study04/41sFSisljvBDMBXtpp5NIw: Retain 400, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 5: study05 #####\n",
      "Fetched 400 tracks!\n",
      "In study05/02iS5AFGp8YVuUUqcQf8ys: Retain 400, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 6: study06 #####\n",
      "Fetched 400 tracks!\n",
      "In study06/6KI7A4MWrSM7EyKRUjxIi1: Retain 400, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 7: study07 #####\n",
      "Fetched 400 tracks!\n",
      "In study07/3V055Md2JdrUT8tX0af7di: Retain 400, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 8: study08 #####\n",
      "Fetched 396 tracks!\n",
      "In study08/0tspdJlwSgiyf2O9PO6QaP: Retain 396, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 9: study09 #####\n",
      "Fetched 395 tracks!\n",
      "In study09/5mHRBFoQtYy2izeZ66pG95: Retain 395, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 10: study10 #####\n",
      "Fetched 404 tracks!\n",
      "In study10/3832xeKGEOAXFJqE4K8kIq: Retain 404, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 11: study11 #####\n",
      "Fetched 381 tracks!\n",
      "In study11/65MXR4dubPL9t0P4dgTWvn: Retain 381, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 12: study12 #####\n",
      "Fetched 357 tracks!\n",
      "In study12/0ecSAfnD4CulIVnLt26ukI: Retain 357, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 13: study13 #####\n",
      "Fetched 377 tracks!\n",
      "In study13/7K9ucByFRgDuZk8KMHeJkL: Retain 377, Dump 0, Valid? True\n",
      "\n",
      "##### Playlist 14: zd_Over #####\n",
      "Fetched 379 tracks!\n",
      "In zd_Over/0v26bHydUxcGC5EbMlkjzG: Retain 379, Dump 0, Valid? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobList = create_dupe_removal_jobs( playlist )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d02ed-a301-47d7-80a0-5368994087ba",
   "metadata": {},
   "source": [
    "# Move Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac26265-6dde-4628-98d5-303561121d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## About to run 14 jobs ... ##########\n",
      "\n",
      "##### Job 1: 0a2qoe6S7lYeZ6nlhZdA0v, 0 to remove ... #####\n",
      "\n",
      "##### Job 2: 6gbtR2cBq5PvkghidCvvGk, 0 to remove ... #####\n",
      "\n",
      "##### Job 3: 3o3lN2qntdEV7UKTuuC77K, 0 to remove ... #####\n",
      "\n",
      "##### Job 4: 41sFSisljvBDMBXtpp5NIw, 0 to remove ... #####\n",
      "\n",
      "##### Job 5: 02iS5AFGp8YVuUUqcQf8ys, 0 to remove ... #####\n",
      "\n",
      "##### Job 6: 6KI7A4MWrSM7EyKRUjxIi1, 0 to remove ... #####\n",
      "\n",
      "##### Job 7: 3V055Md2JdrUT8tX0af7di, 0 to remove ... #####\n",
      "\n",
      "##### Job 8: 0tspdJlwSgiyf2O9PO6QaP, 4 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 0tspdJlwSgiyf2O9PO6QaP ...\n",
      "\tRemove: 46CjJuu0mQ6nRhdAeLNjeA 387\n",
      "\tRemove: 0JLC4Jau2HZT5ZWLl89Lyy 392\n",
      "\tRemove: 1HTnyvQzCoFbOoKIEcv3Lx 393\n",
      "\tRemove: 715mzRnO46sUW5P9ebzzMn 393\n",
      "\n",
      "##### Job 9: 5mHRBFoQtYy2izeZ66pG95, 5 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 5mHRBFoQtYy2izeZ66pG95 ...\n",
      "\tRemove: 6IHfOv402yBlHelEE0ZXdQ 20\n",
      "\tRemove: 0CMGkxUMxhrXX0TK74mYV3 74\n",
      "\tRemove: 1LGleIkBmA6xuiD2bUXUQ4 132\n",
      "\tRemove: 1XqtZl03KLcc4pxqgvAOxu 288\n",
      "\tRemove: 3i6aEW2EMzqJsMYrnvWtAq 350\n",
      "\n",
      "##### Job 10: 3832xeKGEOAXFJqE4K8kIq, 17 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 3832xeKGEOAXFJqE4K8kIq ...\n",
      "\tRemove: 5CfsEeMpceB4gH3cd0Z16H 9\n",
      "\tRemove: 6XbLmtOWP4WzYoAygaiC5t 14\n",
      "\tRemove: 3DvdDu99fW5qQbvMvtapyG 91\n",
      "\tRemove: 73NkbKfbLucJjsWwv4Mqxj 91\n",
      "\tRemove: 2eVIEaJWr9xt4yBrzPAmm0 91\n",
      "\tRemove: 11zcaWAlWNALL7dwhAJFtf 93\n",
      "\tRemove: 6lGnA0hk0an2paDmDMp1go 94\n",
      "\tRemove: 6esvxhHZZesixgBQN3tG9p 129\n",
      "\tRemove: 0CMGkxUMxhrXX0TK74mYV3 174\n",
      "\tRemove: 1xLjomb7h1WgR1YREjMMsO 175\n",
      "\tRemove: 0IiRbRGT4yYlinBKrJSOMw 181\n",
      "\tRemove: 4bSgGZOP2J5hZWNgwM9Tl0 181\n",
      "\tRemove: 2sMO7JZEaBSjrcXRW9iovA 194\n",
      "\tRemove: 2q3vcsAoKdWMwMdQOEKQOT 283\n",
      "\tRemove: 1LGleIkBmA6xuiD2bUXUQ4 348\n",
      "\tRemove: 1oQGkdT9kbPWDpzxA4btOG 350\n",
      "\tRemove: 6spC3h8ozSW4TRMuH5hgIV 350\n",
      "\n",
      "##### Job 11: 65MXR4dubPL9t0P4dgTWvn, 19 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 65MXR4dubPL9t0P4dgTWvn ...\n",
      "\tRemove: 5xajFqT6EFuJlItBtUCczA 351\n",
      "\tRemove: 3IRJ2UmB67KgitNME9NRwE 352\n",
      "\tRemove: 08EpLIL9nOJGYK2TSrrWgY 352\n",
      "\tRemove: 5ZwlkzVzr4PAKYcSzbOA73 352\n",
      "\tRemove: 6kJigPz5SCJPZ1qmFKdqZP 352\n",
      "\tRemove: 0ScjxJ4I1JjoDYwndut66X 352\n",
      "\tRemove: 5UXtaGvQRTxmPlCSLuNlCI 352\n",
      "\tRemove: 6KJG7motGjnVOAiVFlZwNt 352\n",
      "\tRemove: 00Q1iLp0ZSkXNYWltVkFyo 352\n",
      "\tRemove: 2KAFDT6I34FWAn7OKKCKRY 352\n",
      "\tRemove: 0QMqz74lcTkEXJRVFcRmiG 352\n",
      "\tRemove: 2qFETFPD0v3ioiXPeyRvCN 352\n",
      "\tRemove: 0ZWYP8y1sWadiDape078ga 353\n",
      "\tRemove: 7nvzfhh537zC5V3Q53EmmE 353\n",
      "\tRemove: 7x9wWnRSdSFytiX6VuS0VF 353\n",
      "\tRemove: 39mrESMhnclTZ86WFgNA0F 353\n",
      "\tRemove: 0BsdA0U9LKqC72QDRWxylb 353\n",
      "\tRemove: 0ZiSasmccRD5Y9hTe0FrqR 353\n",
      "\tRemove: 7KNt9LUzi36c5pdbFFzFux 353\n",
      "\n",
      "##### Job 12: 0ecSAfnD4CulIVnLt26ukI, 43 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 0ecSAfnD4CulIVnLt26ukI ...\n",
      "\tRemove: 3IRJ2UmB67KgitNME9NRwE 357\n",
      "\tRemove: 08EpLIL9nOJGYK2TSrrWgY 357\n",
      "\tRemove: 5ZwlkzVzr4PAKYcSzbOA73 357\n",
      "\tRemove: 6kJigPz5SCJPZ1qmFKdqZP 357\n",
      "\tRemove: 0ScjxJ4I1JjoDYwndut66X 357\n",
      "\tRemove: 5UXtaGvQRTxmPlCSLuNlCI 357\n",
      "\tRemove: 6KJG7motGjnVOAiVFlZwNt 357\n",
      "\tRemove: 00Q1iLp0ZSkXNYWltVkFyo 357\n",
      "\tRemove: 2KAFDT6I34FWAn7OKKCKRY 357\n",
      "\tRemove: 0QMqz74lcTkEXJRVFcRmiG 357\n",
      "\tRemove: 2qFETFPD0v3ioiXPeyRvCN 357\n",
      "\tRemove: 0jTPZmNEiVa3mFZfyryXYD 357\n",
      "\tRemove: 0ZWYP8y1sWadiDape078ga 357\n",
      "\tRemove: 7nvzfhh537zC5V3Q53EmmE 357\n",
      "\tRemove: 7x9wWnRSdSFytiX6VuS0VF 357\n",
      "\tRemove: 39mrESMhnclTZ86WFgNA0F 357\n",
      "\tRemove: 0BsdA0U9LKqC72QDRWxylb 357\n",
      "\tRemove: 0ZiSasmccRD5Y9hTe0FrqR 357\n",
      "\tRemove: 7KNt9LUzi36c5pdbFFzFux 357\n",
      "\tRemove: 0SwG66vGTBLrqecF13BGBs 357\n",
      "\tRemove: 4pyumoHAKNQMdtmOQa9BKk 357\n",
      "\tRemove: 2BKrQteKQNH1nhkHr9nOic 357\n",
      "\tRemove: 1XGCjkH82ElSNSDEYeD8kN 357\n",
      "\tRemove: 3spr3GTqhgRvge6nkzdQ15 357\n",
      "\tRemove: 7gar3akpYlUG4AgiRyL60R 357\n",
      "\tRemove: 7qRxR6WI4DNVERkXkbezwM 357\n",
      "\tRemove: 2I8wNtxqhImSSY2r6TuA39 357\n",
      "\tRemove: 62HTXDJZNwaYX6o7M6sYrk 357\n",
      "\tRemove: 4c0ci7LUDXcWMe7CaV1tpX 357\n",
      "\tRemove: 4FtctcOTGgwZTUvu0XV2bO 357\n",
      "\tRemove: 3NdQsPe5y3PmpLH9dGboeD 357\n",
      "\tRemove: 1eppWFypvho6Bx0V4vkHo4 357\n",
      "\tRemove: 7wmTmgKO62qNQlkxHjGgC8 357\n",
      "\tRemove: 2tTV7Y7WMwFTmugo1CiOwm 357\n",
      "\tRemove: 6w97hcru1f5mdKkpvuWVXg 357\n",
      "\tRemove: 2DvWWZYnWAYj9A0sSyll7I 357\n",
      "\tRemove: 189PRVLfbfylWWrrosGbEV 357\n",
      "\tRemove: 2ueG7ujMIBCUvFTGDmpODF 357\n",
      "\tRemove: 5gU6oziC1SWJTVgtYzzqaV 357\n",
      "\tRemove: 1LA9JChLXdmdOXD2vedVRu 357\n",
      "\tRemove: 2MR0RW4pLdA2VKcvRpwqt7 357\n",
      "\tRemove: 66eoLT3jyBJMesGe0A8TRI 357\n",
      "\tRemove: 0nN89EPMkLdLsZyDiAnY05 357\n",
      "\n",
      "##### Job 13: 7K9ucByFRgDuZk8KMHeJkL, 23 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 7K9ucByFRgDuZk8KMHeJkL ...\n",
      "\tRemove: 2wMEBVihB2d488dLFPZAVG 350\n",
      "\tRemove: 2LBEp8aPfbB3ITI0RS0J8z 350\n",
      "\tRemove: 1whtUdQvJwJTt9QYiCi71S 350\n",
      "\tRemove: 6xXFChHOjkKb5u0ePIhGrw 350\n",
      "\tRemove: 1d73BkXKlkR99VGWngcC4b 350\n",
      "\tRemove: 0JqJfdeRBTK6CgjpmuPymd 350\n",
      "\tRemove: 6rcVeQnCdvyZ9vOjuBYUYE 350\n",
      "\tRemove: 34j6lNY7zytY2ScEibmjDN 350\n",
      "\tRemove: 02CzJfm7EhHODJitbdOIlN 350\n",
      "\tRemove: 1CIrF6CGjOiOKliWxnOmgI 350\n",
      "\tRemove: 4TCeX9OUN5KYxmoWfepru9 350\n",
      "\tRemove: 6eBnmOdvfZPkICKyoOCUgW 350\n",
      "\tRemove: 72HwmVCghPbJW1i5SksCs0 350\n",
      "\tRemove: 1BWNPVfN9c8G9rzUTxFgYm 350\n",
      "\tRemove: 1dRNdVLQkiJPXUZACcSWKR 350\n",
      "\tRemove: 3DUHsPW0PlUJv98ynZpNDP 350\n",
      "\tRemove: 55nJAhoyaNpq1NhFrc1CtD 350\n",
      "\tRemove: 0g4OGuXsXwJMGDDgQpHqbO 350\n",
      "\tRemove: 0R1DZ426GaqvSLciaCweMV 350\n",
      "\tRemove: 4c0zOypRledzaKDx8NYJA7 350\n",
      "\tRemove: 4aqS95BqtYLqhR3tRbrshL 350\n",
      "\tRemove: 1nLHDeW9SOshCLJll4dnjK 350\n",
      "\tRemove: 0KLzrrVTDVhsbm2utAprTr 350\n",
      "\n",
      "##### Job 14: 0v26bHydUxcGC5EbMlkjzG, 3 to remove ... #####\n",
      "Venting dupes to 1VPXM7m1by79EdEzDqGsHy ...\n",
      "removing dupes from 0v26bHydUxcGC5EbMlkjzG ...\n",
      "\tRemove: 1D6nZSNcmstNpFmxtK50hu 315\n",
      "\tRemove: 73NkbKfbLucJjsWwv4Mqxj 329\n",
      "\tRemove: 3NdQsPe5y3PmpLH9dGboeD 354\n",
      "\n",
      "########## Completed 14 jobs! ##########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_dupe_removal_jobs( jobList, dupeDump, pause_s = 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3aa84-5f68-49a9-aa89-aee9f3628394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
